{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"143f9c02-8d86-484a-b4c2-eb1317289f2a","_uuid":"068dcfb3-c368-468d-8410-aea88bc0b181","id":"oaDoHbxVH0CW"},"source":["# BERT Financial Conditioning"]},{"cell_type":"markdown","metadata":{"_cell_guid":"b5ba98a0-9590-4ccd-b238-cfae63d19770","_uuid":"6a6076dd-8ce5-47e2-8913-74dcaa2eacf0","id":"z_cBqdYOoY5S"},"source":["# Notebook Environment"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"44c8b09f-6f40-410d-aa3c-89b119fb2456","_uuid":"56c0c199-418e-4fa2-a71a-30d54c3a8b2c","collapsed":false,"execution":{"iopub.execute_input":"2024-05-05T13:14:49.195572Z","iopub.status.busy":"2024-05-05T13:14:49.195258Z","iopub.status.idle":"2024-05-05T13:14:49.333266Z","shell.execute_reply":"2024-05-05T13:14:49.332490Z","shell.execute_reply.started":"2024-05-05T13:14:49.195542Z"},"id":"eETPYJLiMU-b","jupyter":{"outputs_hidden":false},"outputId":"49f77cf0-e6a3-44d8-9dae-05a929fa4804","trusted":true},"outputs":[],"source":["UPGRADE_PY = False\n","INSTALL_DEPS = False\n","if INSTALL_DEPS:\n","  # !pip install -q tensorboard==2.15.2\n","  # !pip install -q tensorflow[and-cuda]==2.15.1\n","  # !pip install -q tensorflow==2.15.0\n","  # !pip install -q tensorflow-io-gcs-filesystem==0.36.0\n","  # !pip install -q tensorflow-text==2.15.0\n","  # !pip install -q tf_keras==2.15.1\n","  # !pip install -q tokenizers==0.15.2\n","  # !pip install -q torch==2.2.0+cpu\n","  # !pip install -q torch-xla==2.2.0+libtpu\n","  # !pip install -q torchdata==0.7.1\n","  !pip install -q transformers==4.38.2\n","\n","if UPGRADE_PY:\n","    !mamba create -n py311 -y\n","    !source /opt/conda/bin/activate py312 && mamba install python=3.11 jupyter mamba -y\n","\n","    !sudo rm /opt/conda/bin/python3\n","    !sudo ln -sf /opt/conda/envs/py312/bin/python3 /opt/conda/bin/python3\n","    !sudo rm /opt/conda/bin/python3.10\n","    !sudo ln -sf /opt/conda/envs/py312/bin/python3 /opt/conda/bin/python3.10\n","    !sudo rm /opt/conda/bin/python\n","    !sudo ln -sf /opt/conda/envs/py312/bin/python3 /opt/conda/bin/python\n","\n","!python --version"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cf2e55fb-0872-49df-ae06-aa49505f9474","_uuid":"ccc8fcee-37e2-48b5-8501-6285d13e13cd","collapsed":false,"execution":{"iopub.execute_input":"2024-05-05T13:14:49.335104Z","iopub.status.busy":"2024-05-05T13:14:49.334860Z","iopub.status.idle":"2024-05-05T13:14:49.570166Z","shell.execute_reply":"2024-05-05T13:14:49.569295Z","shell.execute_reply.started":"2024-05-05T13:14:49.335079Z"},"id":"Q4-GoceIIfT_","jupyter":{"outputs_hidden":false},"outputId":"7dcb11f2-d20e-4714-e4fe-f9895dc22aac","trusted":true},"outputs":[],"source":["import os\n","import sys\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# Transformers cannot use keras3\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","os.environ['TF_USE_LEGACY_KERAS'] = '1'\n","IN_KAGGLE = IN_COLAB = False\n","!export CUDA_LAUNCH_BLOCKING=1\n","!export XLA_FLAGS=--xla_cpu_verbose=0\n","\n","try:\n","    # https://www.tensorflow.org/install/pip#windows-wsl2\n","    import google.colab\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    DATA_PATH = \"/content/drive/MyDrive/EDT dataset\"\n","    MODEL_PATH = \"/content/drive/MyDrive/models\"\n","    IN_COLAB = True\n","    print('Colab!')\n","except:\n","    IN_COLAB = False\n","if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ and not IN_COLAB:\n","    print('Running in Kaggle...')\n","    for dirname, _, filenames in os.walk('/kaggle/input'):\n","        for filename in filenames:\n","            print(os.path.join(dirname, filename))\n","    MODEL_PATH = \"./models\"\n","    DATA_PATH = \"/kaggle/input\"\n","    IN_KAGGLE = True\n","    print('Kaggle!')\n","elif not IN_COLAB and not IN_KAGGLE:\n","    IN_KAGGLE = False\n","    MODEL_PATH = \"./models\"\n","    DATA_PATH = \"./data\"\n","    print('Normal!')\n","\n","MODEL_CONDITIONED_PATH = f\"{MODEL_PATH}/model\"\n","MODEL_BASE_CASED = \"google-bert/bert-base-cased\"\n","MODEL_BASE_UNCASED = \"google-bert/bert-base-uncased\""]},{"cell_type":"markdown","metadata":{"_cell_guid":"5f9597e0-9dcb-4671-8317-8f8ac49aec33","_uuid":"d3a0a4f8-0c06-4c8a-992c-40e5326f1f0d","id":"b-qBL7v5oY5T"},"source":["# Accelerators Configuration"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f49d78b5-625d-4f72-a9e6-acf6e43e8bc0","_uuid":"79416aa2-9d9e-4f96-8a41-650f158420fe","collapsed":false,"execution":{"iopub.execute_input":"2024-05-05T13:14:49.571631Z","iopub.status.busy":"2024-05-05T13:14:49.571397Z","iopub.status.idle":"2024-05-05T13:15:02.176661Z","shell.execute_reply":"2024-05-05T13:15:02.175680Z","shell.execute_reply.started":"2024-05-05T13:14:49.571604Z"},"id":"GJiIs_h-H0Ca","jupyter":{"outputs_hidden":false},"outputId":"6c60aab2-ba24-4123-8f02-011e5776646b","trusted":true},"outputs":[],"source":["import numpy as np\n","import math\n","import shutil\n","import pandas as pd\n","\n","from tqdm import tqdm\n","\n","import torch\n","import tensorflow as tf\n","from tensorflow.keras import mixed_precision\n","\n","print(f'Tensorflow version: [{tf.__version__}]')\n","\n","tf.get_logger().setLevel('INFO')\n","\n","#tf.config.set_soft_device_placement(True)\n","#tf.config.experimental.enable_op_determinism()\n","#tf.random.set_seed(1)\n","try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.TPUStrategy(tpu)\n","except Exception as e:\n","    # Not an exception, just no TPUs available, GPU is fallback\n","    # https://www.tensorflow.org/guide/mixed_precision\n","    print(e)\n","    policy = mixed_precision.Policy('mixed_float16')\n","    mixed_precision.set_global_policy(policy)\n","    gpus = tf.config.experimental.list_physical_devices('GPU')\n","    if len(gpus) > 0:\n","\n","        try:\n","            for gpu in gpus:\n","                tf.config.experimental.set_memory_growth(gpu, False)\n","            tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=12288)])\n","            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","            strategy = tf.distribute.MirroredStrategy()\n","\n","            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","        except RuntimeError as e:\n","            print(e)\n","        finally:\n","            print(\"Running on\", len(tf.config.list_physical_devices('GPU')), \"GPU(s)\")\n","    else:\n","        # CPU is final fallback\n","        strategy = tf.distribute.get_strategy()\n","        print(\"Running on CPU\")\n","\n","def is_tpu_strategy(strategy):\n","    return isinstance(strategy, tf.distribute.TPUStrategy)\n","\n","print(\"Number of accelerators:\", strategy.num_replicas_in_sync)\n","os.getcwd()"]},{"cell_type":"markdown","metadata":{"_cell_guid":"aad8b99c-12c7-4cc7-aa16-3a4df29987a6","_uuid":"1e4af399-c728-4867-a49e-4f4d15fa7343"},"source":["# Conditioning with Masked Models"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"62831c0c-4358-4d92-a12c-ec7fd035d257","_uuid":"6eaf57e8-62c3-4f04-b6cb-70f929896aa5","collapsed":false,"execution":{"iopub.execute_input":"2024-05-05T13:15:02.178510Z","iopub.status.busy":"2024-05-05T13:15:02.177881Z","iopub.status.idle":"2024-05-05T13:15:05.006563Z","shell.execute_reply":"2024-05-05T13:15:05.005366Z","shell.execute_reply.started":"2024-05-05T13:15:02.178466Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["from transformers import BertTokenizerFast,TFBertForMaskedLM\n","\n","# https://huggingface.co/transformers/v3.0.2/model_doc/bert.html#berttokenizerfast\n","tokenizer = BertTokenizerFast.from_pretrained(MODEL_BASE_CASED)\n","MASK = tokenizer.mask_token\n","\n","masked_text = [f\"Jim Cramer is consistently bullish when it comes to {MASK}. What this means in practicality is that Cramer routinely recommends buying stocks, and he rarely offers up a sell call. Analysis of his recommendations between 2016 and 2022 (via the data project Jim Cramer's Recommendations: A Six-Year Analysis) shows a 10.32% distribution of {MASK} recommendations alongside 61.27% buys, plus a smattering of positive or negative commentary without a formal buy or sell recommendation attached.\"]\n","\n","inputs = tokenizer(masked_text, return_tensors=\"tf\", padding=True, truncation=True)\n","\n","model = TFBertForMaskedLM.from_pretrained(MODEL_BASE_CASED)\n","logits = model(**inputs).logits\n","mask_token_idxs = tf.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)\n","print(mask_token_idxs)\n","print(logits)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2b826171-3c13-413c-9cea-f0b590af13c3","_uuid":"7c6b679a-1210-4157-991a-f51bd8b4d49a","collapsed":false,"execution":{"iopub.execute_input":"2024-05-05T13:15:05.009099Z","iopub.status.busy":"2024-05-05T13:15:05.008821Z","iopub.status.idle":"2024-05-05T13:15:05.030772Z","shell.execute_reply":"2024-05-05T13:15:05.029819Z","shell.execute_reply.started":"2024-05-05T13:15:05.009073Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["mask_logits = tf.gather_nd(logits, mask_token_idxs)\n","top_5 = tf.math.top_k(mask_logits, k=5)\n","[tokenizer.decode([idx]) for idx in top_5.indices.numpy().flatten()]\n","for i in range(5):\n","    new_text = masked_text[0]\n","    for j in range(2):\n","        token_idx = top_5.indices[j, i]\n","        top5_logits = top_5.values[j]\n","\n","        proba = tf.nn.softmax(top5_logits)\n","        predicted_token = tokenizer.decode([token_idx])\n","        new_text = new_text.replace(MASK, f'[{predicted_token}:{proba[i].numpy()*100.:.01f}%]', 1)\n","    print(new_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9e8f9835-9379-4b37-8601-e4c8173a7a82","_uuid":"141c04d4-e058-473e-8961-380676d5f807","collapsed":false,"execution":{"iopub.execute_input":"2024-05-05T13:15:05.032207Z","iopub.status.busy":"2024-05-05T13:15:05.031912Z","iopub.status.idle":"2024-05-05T13:15:05.154957Z","shell.execute_reply":"2024-05-05T13:15:05.153908Z","shell.execute_reply.started":"2024-05-05T13:15:05.032178Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["adapt_train_file = os.path.join(DATA_PATH, 'Domain_adapation/train.txt')\n","adapt_test_file = os.path.join(DATA_PATH, 'Domain_adapation/dev.txt')\n","def text_dataset(tokenizer, file_path):\n","    def generator():\n","        with open(file_path, 'r', encoding='utf-8') as file:\n","            for line in tqdm(file, desc=\"text_dataset\"):\n","                tokens = tokenizer(line.strip(),\n","                                   add_special_tokens=True,\n","                                   truncation=False,\n","                                   padding=False)\n","                yield {\n","                    'input_ids': tf.ragged.constant([tokens['input_ids']]),\n","                    'attention_mask': tf.ragged.constant([tokens['attention_mask']])\n","                }\n","    return tf.data.Dataset.from_generator(\n","        generator,\n","        output_signature={\n","            'input_ids': tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int32),\n","            'attention_mask': tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int32)\n","        })\n","\n","train_dataset = text_dataset(tokenizer, adapt_train_file)\n","eval_dataset = text_dataset(tokenizer, adapt_test_file)\n","\n","iterator = iter(eval_dataset.as_numpy_iterator())\n","example = next(iterator)\n","inputs = example['input_ids'][0]\n","print(f\"Input IDs (len: {len(inputs)}):\", inputs)\n","print(\"Attention Mask:\", example['attention_mask'])"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bb0b6b2f-039a-4ffc-a657-9dae0ed14bab","_uuid":"348780db-dba6-4b85-87ac-bd1bf0eaa66c","collapsed":false,"execution":{"iopub.execute_input":"2024-05-05T13:15:05.156208Z","iopub.status.busy":"2024-05-05T13:15:05.155958Z","iopub.status.idle":"2024-05-05T13:15:26.023306Z","shell.execute_reply":"2024-05-05T13:15:26.022166Z","shell.execute_reply.started":"2024-05-05T13:15:05.156184Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def chunked_text_dataset(tokenizer, file_path, chunk_len=512):\n","    all_tokens = []\n","    all_attention_masks = []\n","    all_special_tokens_masks = []\n","\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        for line in tqdm(file, desc=\"Reading file lines\", position=0, leave=True):\n","            tokens = tokenizer(line.strip(),\n","                               truncation=True,\n","                               add_special_tokens=True,\n","                               return_special_tokens_mask=True,\n","                               padding=False)\n","            all_tokens.extend(tokens['input_ids'])\n","            all_attention_masks.extend(tokens['attention_mask'])\n","            all_special_tokens_masks.extend(tokens['special_tokens_mask'])\n","\n","    def generator():\n","        num_chunks = len(all_tokens) // chunk_len\n","        for i in tqdm(range(num_chunks), desc= \"chunking...\", position=0, leave=True):\n","            start = i * chunk_len\n","            end = start + chunk_len\n","            input_ids_chunk = all_tokens[start:end]\n","            attention_mask_chunk = all_attention_masks[start:end]\n","            special_tokens_mask_chunk = all_special_tokens_masks[start:end]\n","            yield {\n","                'input_ids': tf.convert_to_tensor(input_ids_chunk, dtype=tf.int32),\n","                'attention_mask': tf.convert_to_tensor(attention_mask_chunk, dtype=tf.int32),\n","                'labels': tf.convert_to_tensor(input_ids_chunk, dtype=tf.int32),\n","                'special_tokens_mask': tf.convert_to_tensor(special_tokens_mask_chunk, dtype=tf.int32)\n","            }\n","\n","    return tf.data.Dataset.from_generator(\n","        generator,\n","        output_signature={\n","            'input_ids': tf.TensorSpec(shape=(chunk_len,), dtype=tf.int32),\n","            'attention_mask': tf.TensorSpec(shape=(chunk_len,), dtype=tf.int32),\n","            'labels': tf.TensorSpec(shape=(chunk_len,), dtype=tf.int32),\n","            'special_tokens_mask': tf.TensorSpec(shape=(chunk_len,), dtype=tf.int32)\n","        })\n","\n","\n","train_dataset = chunked_text_dataset(tokenizer, adapt_train_file)\n","iterator = iter(eval_dataset.as_numpy_iterator())\n","example = next(iterator)\n","inputs = example['input_ids'][0]\n","print(f\"Input IDs (len: {len(inputs)}):\", inputs)\n","print(\"Decoded IDs:\", tokenizer.decode(inputs)[:50])"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b74d415d-ae9e-4f07-8682-f90ed5beb9c7","_uuid":"9b74aa32-40f3-41ce-990b-25f2f5122bbf","collapsed":false,"execution":{"iopub.execute_input":"2024-05-05T13:15:26.024778Z","iopub.status.busy":"2024-05-05T13:15:26.024506Z","iopub.status.idle":"2024-05-05T13:15:28.190858Z","shell.execute_reply":"2024-05-05T13:15:28.189898Z","shell.execute_reply.started":"2024-05-05T13:15:26.024753Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["from transformers import DataCollatorForLanguageModeling, BertConfig\n","\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15, return_tensors=\"tf\")\n","batched_dataset = train_dataset.batch(1).take(1)\n","\n","batch = next(iter(eval_dataset.as_numpy_iterator()))\n","batch = {k: v for k, v in batch.items()}\n","examples = [{k: v[i] for k, v in batch.items()} for i in range(batch['input_ids'].shape[0])]\n","print(examples)\n","collated_batch = data_collator(examples)\n","for input_ids, labels in tqdm(zip(collated_batch['input_ids'], collated_batch['labels']), desc=\"tokenizing batches\"):\n","    masked_text = tokenizer.decode(input_ids)\n","    original_text = tokenizer.decode([label if label != -100 else input_id for label, input_id in zip(labels, input_ids)])\n","\n","    print(f\"Masked: {masked_text[:50]}\")\n","    print(f\"Labels: {labels[:50]}\")\n","    print(f\"Original: {original_text[:50]}\")\n","collated_batch"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c69123c9-0676-4a8a-90f1-341b3dab1436","_uuid":"746ad547-16cc-4b67-9deb-caa8be6d9dae","collapsed":false,"execution":{"iopub.execute_input":"2024-05-05T13:15:28.192450Z","iopub.status.busy":"2024-05-05T13:15:28.192135Z","iopub.status.idle":"2024-05-05T13:16:20.275402Z","shell.execute_reply":"2024-05-05T13:16:20.274314Z","shell.execute_reply.started":"2024-05-05T13:15:28.192419Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["MAX_LEN = 512 # Default 256, MAX 512\n","def mlm_text_dataset(file_path, tokenizer, data_collator, chunk_len=MAX_LEN):\n","    all_tokens = []\n","    all_attention_masks = []\n","    all_special_tokens_masks = []\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        for line in tqdm(file, position=0, leave=True, desc=\"Processing file...\"):\n","            tokens = tokenizer(line.strip(),\n","                               truncation=True,\n","                               add_special_tokens=True,\n","                               return_special_tokens_mask=True,\n","                               padding=False)\n","            all_tokens.extend(tokens['input_ids'])\n","            all_attention_masks.extend(tokens['attention_mask'])\n","            all_special_tokens_masks.extend(tokens['special_tokens_mask'])\n","\n","\n","    num_chunks = len(all_tokens) // chunk_len\n","    tokens_chunks = []\n","    attention_mask_chunks = []\n","    label_chunks = []\n","    special_tokens_mask_chunk=[]\n","    for i in tqdm(range(num_chunks), position=0, leave=True, desc=\"Chunking...\"):\n","        start = i * chunk_len\n","        end = start + chunk_len\n","        input_ids_chunk = all_tokens[start:end]\n","        attention_mask_chunk = all_attention_masks[start:end]\n","        special_tokens_mask_chunk = all_special_tokens_masks[start:end]\n","\n","        masked_chunks = data_collator([{\n","                'input_ids': tf.convert_to_tensor(input_ids_chunk, dtype=tf.int32),\n","                'attention_mask': tf.convert_to_tensor(attention_mask_chunk, dtype=tf.int32),\n","                'special_tokens_mask': tf.convert_to_tensor(special_tokens_mask_chunk, dtype=tf.int32),}])\n","        tokens_chunks.extend(masked_chunks['input_ids'])\n","        label_chunks.extend(masked_chunks['labels'])\n","        attention_mask_chunks.extend(masked_chunks['attention_mask'])\n","        special_tokens_mask_chunk.extend(special_tokens_mask_chunk)\n","    return tf.data.Dataset.from_tensor_slices((\n","        {\n","            'input_ids': tokens_chunks,\n","            'attention_mask': attention_mask_chunks,\n","            'labels': label_chunks,\n","            # 'special_tokens_mask': special_tokens_mask_chunk\n","        },\n","    ))\n","\n","with strategy.scope():\n","    tokenizer = BertTokenizerFast.from_pretrained(MODEL_BASE_CASED)\n","    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15, return_tensors=\"np\")\n","    mlm_train_dataset = mlm_text_dataset(adapt_train_file, tokenizer, data_collator)\n","    mlm_test_dataset = mlm_text_dataset(adapt_test_file, tokenizer, data_collator)\n","\n","iterex = iter(mlm_test_dataset.as_numpy_iterator())\n","next(iterex)"]},{"cell_type":"markdown","metadata":{},"source":["## BERT Conditioning Training Loops\n","\n","Recommended training params from the paper:\n","\n","* Batch size: 16, 32\n","* Learning rate (Adam): 5e-5, 3e-5, 2e-5\n","* Number of epochs: 2, 3, 4"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T13:16:20.276822Z","iopub.status.busy":"2024-05-05T13:16:20.276521Z","iopub.status.idle":"2024-05-05T13:16:20.281731Z","shell.execute_reply":"2024-05-05T13:16:20.280973Z","shell.execute_reply.started":"2024-05-05T13:16:20.276778Z"},"trusted":true},"outputs":[],"source":["MAX_LEN = 512 # Default 256, MAX 512\n","LEARN_RATE=5e-5 # 5e-5\n","PATIENCE=10\n","EPOCHS=50\n","\n","TOTAL_STEPS = 100000\n","WARM_STEPS = 10000\n","INIT_LR = 1e-4\n","BETA_1 = 0.9\n","BETA_2 = 0.999\n","WEIGHT_DECAY = 0.01\n","\n","BATCH_SIZE = 16 * strategy.num_replicas_in_sync # Default 8\n","BUFFER_SIZE = 10000"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T13:16:20.283261Z","iopub.status.busy":"2024-05-05T13:16:20.282855Z","iopub.status.idle":"2024-05-05T13:16:20.599614Z","shell.execute_reply":"2024-05-05T13:16:20.598549Z","shell.execute_reply.started":"2024-05-05T13:16:20.283236Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, TerminateOnNaN\n","from tensorflow.keras.optimizers import AdamW\n","\n","import zipfile\n","\n","import matplotlib.pyplot as plt\n","\n","def eval_mlm(model, batched_dataset):\n","    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.SUM)\n","    total_loss = 0.\n","    total_accuracy = 0.\n","    total_examples = 0.\n","\n","    # TODO: convert this to a TF function for distributed strat.\n","    for batch in tqdm(batched_dataset, desc=\"eval_mlm\", position=0, leave=True):\n","        for dataset_output in batch:\n","            input_ids = dataset_output['input_ids']\n","            attention_mask = dataset_output['attention_mask']\n","            labels = dataset_output['labels']\n","\n","            outputs = model(input_ids, attention_mask=attention_mask)\n","            logits = outputs.logits\n","\n","            mask = (labels != -100)\n","            masked_logits = tf.boolean_mask(logits, mask)\n","            masked_labels = tf.boolean_mask(labels, mask)\n","            batch_loss = loss_fn(masked_labels, masked_logits)\n","            predictions = tf.argmax(masked_logits, axis=-1)\n","            batch_accuracy = tf.reduce_sum(tf.cast(tf.equal(predictions, masked_labels), dtype=tf.float32))\n","\n","            total_loss += tf.cast(batch_loss,tf.float32)\n","            total_accuracy += batch_accuracy\n","            total_examples += tf.size(masked_labels, out_type=tf.float32)\n","\n","    avg_loss = total_loss / total_examples\n","    avg_perplexity = tf.exp(avg_loss).numpy()\n","    avg_accuracy = total_accuracy / total_examples\n","\n","    print(f\"Average Cross-Entropy Loss: {avg_loss.numpy()}\")\n","    print(f\"Average Perplexity: {avg_perplexity}\")\n","    print(f\"Average Accuracy: {avg_accuracy.numpy()}\")\n","\n","\n","\n","def condition_model(model_path, models_log_dir=MODEL_PATH, from_pt=False):\n","    with strategy.scope():\n","        # https://huggingface.co/transformers/v3.0.2/_modules/transformers/configuration_bert.html#BertConfig\n","        config = BertConfig.from_pretrained(model_path, from_pt=from_pt)\n","        cond_model = TFBertForMaskedLM.from_pretrained(model_path, config=config, from_pt=from_pt)\n","\n","        # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard\n","        tensorboard_callback = TensorBoard(log_dir=f\"{models_log_dir}/logs\",\n","                                            histogram_freq=2,\n","                                            embeddings_freq=2)\n","        # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n","        early_stopping = EarlyStopping(mode='min', patience=PATIENCE, start_from_epoch=1)\n","        #tf.debugging.enable_check_numerics() # - Assert if no Infs or NaNs go through. not for TPU!\n","        #tf.config.run_functions_eagerly(not is_tpu_strategy(strategy)) # - Easy debugging\n","        # https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\n","        train_dataset = (mlm_train_dataset.shuffle(buffer_size=BUFFER_SIZE)\n","                                        .batch(BATCH_SIZE)\n","                                        .cache()\n","                                        .prefetch(tf.data.experimental.AUTOTUNE))\n","        test_dataset = (mlm_test_dataset.shuffle(buffer_size=BUFFER_SIZE)\n","                                        .batch(BATCH_SIZE)\n","                                        .cache()\n","                                        .prefetch(tf.data.experimental.AUTOTUNE))\n","        cond_model.compile(optimizer=AdamW(learning_rate=LEARN_RATE))\n","        history = cond_model.fit(train_dataset,\n","                            epochs=EPOCHS,\n","                            callbacks=[early_stopping, TerminateOnNaN()],\n","                            verbose=\"auto\",\n","                            validation_data=test_dataset)\n","\n","        cond_model.save_pretrained(f\"{MODEL_PATH}/model\")\n","        config.save_pretrained(f\"{MODEL_PATH}\")\n","        tokenizer.save_pretrained(f\"{MODEL_PATH}/tokenizer\")\n","\n","        return cond_model, history\n","\n","\n","def plot_training_metrics(history):\n","    epochs = range(1, len(history.history['loss']) + 1)\n","\n","    fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n","\n","    axs[0].plot(epochs, history.history['loss'], 'bo-', label='Training Loss')\n","    axs[0].plot(epochs, history.history['val_loss'], 'ro-', label='Validation Loss')\n","    axs[0].set_title('Training and Validation Loss')\n","    axs[0].set_xlabel('Epochs')\n","    axs[0].set_ylabel('Loss')\n","    axs[0].legend()\n","\n","    train_perplexity = []\n","    validation_perplexity = []\n","    for loss in history.history[\"loss\"]:\n","        try:\n","            epoch_perplexity = math.exp(loss)\n","        except OverflowError:\n","            epoch_perplexity = float('inf')\n","        train_perplexity.append(epoch_perplexity)\n","    for val_loss in history.history.get(\"val_loss\", []):\n","        try:\n","            epoch_perplexity = math.exp(val_loss)\n","        except OverflowError:\n","            epoch_perplexity = float('inf')\n","        validation_perplexity.append(epoch_perplexity)\n","\n","    axs[1].plot(epochs,train_perplexity, 'bo-', label='Training Perplexity')\n","    axs[1].plot(epochs, validation_perplexity, 'ro-', label='Validation Perplexity')\n","    axs[1].set_title('Training and Validation Perplexity')\n","    axs[1].set_xlabel('Epochs')\n","    axs[1].set_ylabel('Perplexity')\n","    axs[1].legend()\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","    results_dict = {}\n","    results_dict[\"train_loss\"] = history.history[\"loss\"][-1]\n","    results_dict[\"eval_loss\"] = history.history[\"val_loss\"][-1]\n","    results_dict[\"train_perplexity\"] = train_perplexity[-1]\n","    results_dict[\"eval_perplexity\"] = validation_perplexity[-1]\n","\n","    return results_dict\n","\n","\n","def zip_models(directory, output_filename, compression_level = 9):\n","    with zipfile.ZipFile(output_filename, 'w', zipfile.ZIP_DEFLATED, compresslevel=compression_level) as zipf:\n","        for root, dirs, files in os.walk(directory):\n","            for file in files:\n","                zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), os.path.join(directory, '..')))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T13:16:20.600921Z","iopub.status.busy":"2024-05-05T13:16:20.600657Z"},"trusted":true},"outputs":[],"source":["# Base Eval\n","config = BertConfig.from_pretrained(MODEL_BASE_UNCASED)\n","model = TFBertForMaskedLM.from_pretrained(MODEL_BASE_UNCASED, config=config)\n","test_dataset = mlm_test_dataset.shuffle(buffer_size=BUFFER_SIZE).batch(BATCH_SIZE).cache().prefetch(tf.data.experimental.AUTOTUNE)\n","eval_mlm(model, test_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["## Base Uncased Conditioned"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b8542448-aed9-4324-9759-cf47b37b5f47","_uuid":"191e97fc-b9b1-4835-870d-4ad8be04a881","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["cond_model, history = condition_model(MODEL_BASE_UNCASED)\n","plot_training_metrics(history)\n","eval_mlm(cond_model, test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["eval_mlm(cond_model, test_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["## Base Cased"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Base Eval\n","config = BertConfig.from_pretrained(MODEL_BASE_CASED)\n","model = TFBertForMaskedLM.from_pretrained(MODEL_BASE_CASED, config=config)\n","test_dataset = mlm_test_dataset.shuffle(buffer_size=BUFFER_SIZE).batch(BATCH_SIZE).cache().prefetch(tf.data.experimental.AUTOTUNE)\n","eval_mlm(model, test_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["## Base Cased Conditioned"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cond_model, history = condition_model(MODEL_BASE_CASED)\n","plot_training_metrics(history)\n","eval_mlm(cond_model, test_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluate FinBERT\n","\n","## Cased FinVocab"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# https://huggingface.co/yiyanghkust/finbert-pretrain\n","# https://github.com/yya518/FinBERT?tab=readme-ov-file\n","FINBERT_MODEL_CASED_PATH = \"radmada/FinBERT-FinVocab-Cased\" # f\"{MODEL_PATH}/FinBERT-FinVocab-Cased\"\n","\n","with strategy.scope():\n","    tokenizer = BertTokenizerFast.from_pretrained(FINBERT_MODEL_CASED_PATH, from_pt=True)\n","\n","    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15, return_tensors=\"np\")\n","    mlm_train_dataset = mlm_text_dataset(adapt_train_file, tokenizer, data_collator)\n","    mlm_test_dataset = mlm_text_dataset(adapt_test_file, tokenizer, data_collator)\n","\n","    config = BertConfig.from_pretrained(FINBERT_MODEL_CASED_PATH, from_pt=True)\n","    model = TFBertForMaskedLM.from_pretrained(FINBERT_MODEL_CASED_PATH, config=config, from_pt=True)\n","    test_dataset = mlm_test_dataset.shuffle(buffer_size=BUFFER_SIZE).batch(BATCH_SIZE).cache().prefetch(tf.data.experimental.AUTOTUNE)\n","\n","    eval_mlm(model, test_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["## Cased FinVocab Conditioned"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cond_model, history = condition_model(FINBERT_MODEL_CASED_PATH, from_pt=True)\n","plot_training_metrics(history)\n","eval_mlm(cond_model, test_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["## Uncased FinVocab"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["FINBERT_MODEL_UNCASED_PATH = f\"{MODEL_PATH}/FinBERT-FinVocab-Uncased\"\n","\n","with strategy.scope():\n","    tokenizer = BertTokenizerFast.from_pretrained(FINBERT_MODEL_UNCASED_PATH, from_pt=True)\n","\n","    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15, return_tensors=\"np\")\n","    mlm_train_dataset = mlm_text_dataset(adapt_train_file, tokenizer, data_collator)\n","    mlm_test_dataset = mlm_text_dataset(adapt_test_file, tokenizer, data_collator)\n","\n","    config = BertConfig.from_pretrained(FINBERT_MODEL_UNCASED_PATH, from_pt=True)\n","    model = TFBertForMaskedLM.from_pretrained(FINBERT_MODEL_UNCASED_PATH, config=config, from_pt=True)\n","    test_dataset = mlm_test_dataset.shuffle(buffer_size=BUFFER_SIZE).batch(BATCH_SIZE).cache().prefetch(tf.data.experimental.AUTOTUNE)\n","\n","    eval_mlm(model, test_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["## Uncased FinVocab Conditioned"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cond_model, history = condition_model(FINBERT_MODEL_UNCASED_PATH, from_pt=True)\n","plot_training_metrics(history)\n","eval_mlm(cond_model, test_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["## Cased Base"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["FINBERT_BASEMODEL_CASED_PATH = f\"{MODEL_PATH}/FinBERT-BaseVocab-Cased\"\n","\n","with strategy.scope():\n","    tokenizer = BertTokenizerFast.from_pretrained(FINBERT_BASEMODEL_CASED_PATH, from_pt=True)\n","\n","    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15, return_tensors=\"np\")\n","    mlm_train_dataset = mlm_text_dataset(adapt_train_file, tokenizer, data_collator)\n","    mlm_test_dataset = mlm_text_dataset(adapt_test_file, tokenizer, data_collator)\n","\n","    config = BertConfig.from_pretrained(FINBERT_BASEMODEL_CASED_PATH, from_pt=True)\n","    model = TFBertForMaskedLM.from_pretrained(FINBERT_BASEMODEL_CASED_PATH, config=config, from_pt=True)\n","    test_dataset = mlm_test_dataset.shuffle(buffer_size=BUFFER_SIZE).batch(BATCH_SIZE).cache().prefetch(tf.data.experimental.AUTOTUNE)\n","\n","    eval_mlm(model, test_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["## Cased Base Conditioned"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cond_model, history = condition_model(FINBERT_BASEMODEL_CASED_PATH, from_pt=True)\n","plot_training_metrics(history)\n","eval_mlm(cond_model, test_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["## Uncased Base"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["FINBERT_BASEMODEL_UNCASED_PATH = f\"{MODEL_PATH}/FinBERT-BaseVocab-Uncased\"\n","\n","with strategy.scope():\n","    tokenizer = BertTokenizerFast.from_pretrained(FINBERT_BASEMODEL_UNCASED_PATH, from_pt=True)\n","\n","    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15, return_tensors=\"np\")\n","    mlm_train_dataset = mlm_text_dataset(adapt_train_file, tokenizer, data_collator)\n","    mlm_test_dataset = mlm_text_dataset(adapt_test_file, tokenizer, data_collator)\n","\n","    config = BertConfig.from_pretrained(FINBERT_BASEMODEL_UNCASED_PATH, from_pt=True)\n","    model = TFBertForMaskedLM.from_pretrained(FINBERT_BASEMODEL_UNCASED_PATH, config=config, from_pt=True)\n","    test_dataset = mlm_test_dataset.shuffle(buffer_size=BUFFER_SIZE).batch(BATCH_SIZE).cache().prefetch(tf.data.experimental.AUTOTUNE)\n","\n","    eval_mlm(model, test_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["## Uncased Conditioned"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cond_model, history = condition_model(FINBERT_BASEMODEL_UNCASED_PATH, from_pt=True)\n","plot_training_metrics(history)\n","eval_mlm(cond_model, test_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["# Combining Vocabs\n","\n","\n","## Cased"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["finbert_tokenizer = BertTokenizerFast.from_pretrained(FINBERT_MODEL_CASED_PATH)\n","bert_cased_tokenizer = BertTokenizerFast.from_pretrained(MODEL_BASE_CASED)\n","\n","finbert_vocab = finbert_tokenizer.get_vocab()\n","bert_cased_vocab = bert_cased_tokenizer.get_vocab()\n","finbert_vocab_set = set(finbert_vocab.keys())\n","bert_cased_vocab_set = set(bert_cased_vocab.keys())\n","\n","combined_vocab = finbert_vocab_set.union(bert_cased_vocab_set)\n","print(list(combined_vocab)[:25]) # check the vocab\n","\n","COMBI_CASED_VOCAB_PATH = f\"{MODEL_PATH}/vocabs/vocab.txt\"\n","\n","os.makedirs(f\"{MODEL_PATH}/vocabs\", exist_ok=True)\n","with open(COMBI_CASED_VOCAB_PATH, 'w', encoding='utf-8') as file:\n","    for token in sorted(combined_vocab):\n","        file.write(token + '\\n')\n","    print(f\"Saved to {COMBI_CASED_VOCAB_PATH}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["with strategy.scope():\n","    tokenizer = BertTokenizerFast(vocab_file=COMBI_CASED_VOCAB_PATH, do_lower_case=False)\n","\n","    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15, return_tensors=\"np\")\n","    mlm_train_dataset = mlm_text_dataset(adapt_train_file, tokenizer, data_collator)\n","    mlm_test_dataset = mlm_text_dataset(adapt_test_file, tokenizer, data_collator)\n","\n","    config = BertConfig.from_pretrained(FINBERT_MODEL_CASED_PATH)\n","\n","    model = TFBertForMaskedLM.from_pretrained(FINBERT_MODEL_CASED_PATH, config=config, from_pt=True)\n","    test_dataset = mlm_test_dataset.shuffle(buffer_size=BUFFER_SIZE).batch(BATCH_SIZE).cache().prefetch(tf.data.experimental.AUTOTUNE)\n","    eval_mlm(model, test_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["## Uncased"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["finbert_tokenizer = BertTokenizerFast.from_pretrained(FINBERT_MODEL_UNCASED_PATH)\n","bert_cased_tokenizer = BertTokenizerFast.from_pretrained(MODEL_BASE_UNCASED)\n","\n","finbert_vocab = finbert_tokenizer.get_vocab()\n","bert_cased_vocab = bert_cased_tokenizer.get_vocab()\n","finbert_vocab_set = set(finbert_vocab.keys())\n","bert_cased_vocab_set = set(bert_cased_vocab.keys())\n","\n","combined_vocab = finbert_vocab_set.union(bert_cased_vocab_set)\n","print(list(combined_vocab)[:25]) # check the vocab\n","\n","COMBI_UNCASED_VOCAB_PATH = f\"{MODEL_PATH}/vocabs/vocab.txt\"\n","\n","os.makedirs(f\"{MODEL_PATH}/vocabs\", exist_ok=True)\n","with open(COMBI_CASED_VOCAB_PATH, 'w', encoding='utf-8') as file:\n","    for token in sorted(combined_vocab):\n","        file.write(token + '\\n')\n","    print(f\"Saved to {COMBI_UNCASED_VOCAB_PATH}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["with strategy.scope():\n","    tokenizer = BertTokenizerFast(vocab_file=COMBI_CASED_VOCAB_PATH, do_lower_case=False)\n","\n","    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15, return_tensors=\"np\")\n","    mlm_train_dataset = mlm_text_dataset(adapt_train_file, tokenizer, data_collator)\n","    mlm_test_dataset = mlm_text_dataset(adapt_test_file, tokenizer, data_collator)\n","\n","    config = BertConfig.from_pretrained(FINBERT_MODEL_CASED_PATH)\n","\n","    model = TFBertForMaskedLM.from_pretrained(FINBERT_MODEL_CASED_PATH, config=config, from_pt=True)\n","    test_dataset = mlm_test_dataset.shuffle(buffer_size=BUFFER_SIZE).batch(BATCH_SIZE).cache().prefetch(tf.data.experimental.AUTOTUNE)\n","    eval_mlm(model, test_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["# Save Best Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["SAVE_ZIP = False\n","\n","if SAVE_ZIP:\n","    zip_models(MODEL_PATH, './cond_bert.zip')"]}],"metadata":{"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"datasetId":4755137,"sourceId":8061237,"sourceType":"datasetVersion"}],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":4}
