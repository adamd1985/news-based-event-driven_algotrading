{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "089f5fe1",
   "metadata": {
    "_cell_guid": "143f9c02-8d86-484a-b4c2-eb1317289f2a",
    "_uuid": "068dcfb3-c368-468d-8410-aea88bc0b181",
    "id": "oaDoHbxVH0CW",
    "papermill": {
     "duration": 0.007996,
     "end_time": "2024-05-04T21:41:27.103845",
     "exception": false,
     "start_time": "2024-05-04T21:41:27.095849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59dadd8",
   "metadata": {
    "_cell_guid": "b5ba98a0-9590-4ccd-b238-cfae63d19770",
    "_uuid": "6a6076dd-8ce5-47e2-8913-74dcaa2eacf0",
    "id": "z_cBqdYOoY5S",
    "papermill": {
     "duration": 0.007287,
     "end_time": "2024-05-04T21:41:27.118613",
     "exception": false,
     "start_time": "2024-05-04T21:41:27.111326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Notebook Environment\n",
    "\n",
    "For a unified research environment, enable the flags below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "979e9fb2",
   "metadata": {
    "_cell_guid": "44c8b09f-6f40-410d-aa3c-89b119fb2456",
    "_uuid": "56c0c199-418e-4fa2-a71a-30d54c3a8b2c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-04T21:41:27.134512Z",
     "iopub.status.busy": "2024-05-04T21:41:27.134072Z",
     "iopub.status.idle": "2024-05-04T21:41:28.106639Z",
     "shell.execute_reply": "2024-05-04T21:41:28.105645Z"
    },
    "id": "eETPYJLiMU-b",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "49f77cf0-e6a3-44d8-9dae-05a929fa4804",
    "papermill": {
     "duration": 0.983471,
     "end_time": "2024-05-04T21:41:28.109168",
     "exception": false,
     "start_time": "2024-05-04T21:41:27.125697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.13\r\n"
     ]
    }
   ],
   "source": [
    "UPGRADE_PY = False\n",
    "INSTALL_DEPS = False\n",
    "if INSTALL_DEPS:\n",
    "  # !pip install -q tensorboard==2.15.2\n",
    "  # !pip install -q tensorflow[and-cuda]==2.15.1\n",
    "  # !pip install -q tensorflow==2.15.0\n",
    "  # !pip install -q tensorflow-io-gcs-filesystem==0.36.0\n",
    "  # !pip install -q tensorflow-text==2.15.0\n",
    "  # !pip install -q tf_keras==2.15.1\n",
    "  # !pip install -q tokenizers==0.15.2\n",
    "  # !pip install -q torch==2.2.0+cpu\n",
    "  # !pip install -q torch-xla==2.2.0+libtpu\n",
    "  # !pip install -q torchdata==0.7.1\n",
    "  !pip install -q transformers==4.38.2\n",
    "\n",
    "if UPGRADE_PY:\n",
    "    !mamba create -n py311 -y\n",
    "    !source /opt/conda/bin/activate py312 && mamba install python=3.11 jupyter mamba -y\n",
    "\n",
    "    !sudo rm /opt/conda/bin/python3\n",
    "    !sudo ln -sf /opt/conda/envs/py312/bin/python3 /opt/conda/bin/python3\n",
    "    !sudo rm /opt/conda/bin/python3.10\n",
    "    !sudo ln -sf /opt/conda/envs/py312/bin/python3 /opt/conda/bin/python3.10\n",
    "    !sudo rm /opt/conda/bin/python\n",
    "    !sudo ln -sf /opt/conda/envs/py312/bin/python3 /opt/conda/bin/python\n",
    "\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "015fcb63",
   "metadata": {
    "_cell_guid": "cf2e55fb-0872-49df-ae06-aa49505f9474",
    "_uuid": "ccc8fcee-37e2-48b5-8501-6285d13e13cd",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-04T21:41:28.125889Z",
     "iopub.status.busy": "2024-05-04T21:41:28.125562Z",
     "iopub.status.idle": "2024-05-04T21:41:30.050163Z",
     "shell.execute_reply": "2024-05-04T21:41:30.049070Z"
    },
    "id": "Q4-GoceIIfT_",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "7dcb11f2-d20e-4714-e4fe-f9895dc22aac",
    "papermill": {
     "duration": 1.935848,
     "end_time": "2024-05-04T21:41:30.052715",
     "exception": false,
     "start_time": "2024-05-04T21:41:28.116867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Kaggle...\n",
      "/kaggle/input/Event_detection/train.txt\n",
      "/kaggle/input/Event_detection/dev.txt\n",
      "/kaggle/input/Trading_benchmark/evaluate_news.json\n",
      "/kaggle/input/Domain_adapation/train.txt\n",
      "/kaggle/input/Domain_adapation/dev.txt\n",
      "Kaggle!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Transformers cannot use keras3\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
    "IN_KAGGLE = IN_COLAB = False\n",
    "!export CUDA_LAUNCH_BLOCKING=1\n",
    "!export XLA_FLAGS=--xla_cpu_verbose=0\n",
    "\n",
    "try:\n",
    "    # https://www.tensorflow.org/install/pip#windows-wsl2\n",
    "    import google.colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    DATA_PATH = \"/content/drive/MyDrive/EDT dataset\"\n",
    "    MODEL_PATH = \"/content/drive/MyDrive/models\"\n",
    "    IN_COLAB = True\n",
    "    print('Colab!')\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ and not IN_COLAB:\n",
    "    print('Running in Kaggle...')\n",
    "    for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "        for filename in filenames:\n",
    "            print(os.path.join(dirname, filename))\n",
    "    MODEL_PATH = \"./models\"\n",
    "    DATA_PATH = \"/kaggle/input\"\n",
    "    IN_KAGGLE = True\n",
    "    print('Kaggle!')\n",
    "elif not IN_COLAB and not IN_KAGGLE:\n",
    "    IN_KAGGLE = False\n",
    "    MODEL_PATH = \"./models\"\n",
    "    DATA_PATH = \"./data\"\n",
    "    print('Normal!')\n",
    "\n",
    "MODEL_BASE = \"google-bert/bert-base-cased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20436981",
   "metadata": {
    "_cell_guid": "5f9597e0-9dcb-4671-8317-8f8ac49aec33",
    "_uuid": "d3a0a4f8-0c06-4c8a-992c-40e5326f1f0d",
    "id": "b-qBL7v5oY5T",
    "papermill": {
     "duration": 0.010325,
     "end_time": "2024-05-04T21:41:30.073816",
     "exception": false,
     "start_time": "2024-05-04T21:41:30.063491",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Accelerators Configuration\n",
    "\n",
    "If you have a GPU, TPU or in one of the collaborative notebooks. Configure your setup below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "818565ed",
   "metadata": {
    "_cell_guid": "f49d78b5-625d-4f72-a9e6-acf6e43e8bc0",
    "_uuid": "79416aa2-9d9e-4f96-8a41-650f158420fe",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-04T21:41:30.092367Z",
     "iopub.status.busy": "2024-05-04T21:41:30.092035Z",
     "iopub.status.idle": "2024-05-04T21:41:43.337291Z",
     "shell.execute_reply": "2024-05-04T21:41:43.336376Z"
    },
    "id": "GJiIs_h-H0Ca",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "6c60aab2-ba24-4123-8f02-011e5776646b",
    "papermill": {
     "duration": 13.256752,
     "end_time": "2024-05-04T21:41:43.339569",
     "exception": false,
     "start_time": "2024-05-04T21:41:30.082817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 21:41:32.684624: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-04 21:41:32.684720: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-04 21:41:32.828505: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: [2.15.0]\n",
      "Please provide a TPU Name to connect to.\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Running on 1 GPU(s)\n",
      "Number of accelerators: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/kaggle/working'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "print(f'Tensorflow version: [{tf.__version__}]')\n",
    "\n",
    "tf.get_logger().setLevel('INFO')\n",
    "\n",
    "#tf.config.set_soft_device_placement(True)\n",
    "#tf.config.experimental.enable_op_determinism()\n",
    "#tf.random.set_seed(1)\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "except Exception as e:\n",
    "    # Not an exception, just no TPUs available, GPU is fallback\n",
    "    # https://www.tensorflow.org/guide/mixed_precision\n",
    "    print(e)\n",
    "    policy = mixed_precision.Policy('mixed_float16')\n",
    "    mixed_precision.set_global_policy(policy)\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if len(gpus) > 0:\n",
    "\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, False)\n",
    "            tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=12288)])\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "        finally:\n",
    "            print(\"Running on\", len(tf.config.list_physical_devices('GPU')), \"GPU(s)\")\n",
    "    else:\n",
    "        # CPU is final fallback\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "        print(\"Running on CPU\")\n",
    "\n",
    "def is_tpu_strategy(strategy):\n",
    "    return isinstance(strategy, tf.distribute.TPUStrategy)\n",
    "\n",
    "print(\"Number of accelerators:\", strategy.num_replicas_in_sync)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199e00b6",
   "metadata": {
    "_cell_guid": "aad8b99c-12c7-4cc7-aa16-3a4df29987a6",
    "_uuid": "1e4af399-c728-4867-a49e-4f4d15fa7343",
    "papermill": {
     "duration": 0.007753,
     "end_time": "2024-05-04T21:41:43.355529",
     "exception": false,
     "start_time": "2024-05-04T21:41:43.347776",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fine-Tuning with Masked Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42d4de6c",
   "metadata": {
    "_cell_guid": "62831c0c-4358-4d92-a12c-ec7fd035d257",
    "_uuid": "6eaf57e8-62c3-4f04-b6cb-70f929896aa5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-04T21:41:43.372700Z",
     "iopub.status.busy": "2024-05-04T21:41:43.372163Z",
     "iopub.status.idle": "2024-05-04T21:41:55.074885Z",
     "shell.execute_reply": "2024-05-04T21:41:55.073923Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 11.713748,
     "end_time": "2024-05-04T21:41:55.077117",
     "exception": false,
     "start_time": "2024-05-04T21:41:43.363369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb4820c3abc44248dce2273e9e15650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da732ad3a2ea4ce88adea0d79c09443e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f33783c970c473494031c09f1a8431e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc5f33f7be624c8ba01443a268f3f63b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b5741ebc1f46da96710085a5cc436e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the weights of TFBertForMaskedLM were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0 13]\n",
      " [ 0 81]], shape=(2, 2), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[ -7.363  -7.258  -7.37  ...  -6.348  -6.03   -6.34 ]\n",
      "  [ -7.21   -7.266  -6.906 ...  -6.49   -5.54   -6.582]\n",
      "  [-11.97  -11.59  -10.73  ...  -9.36   -8.42  -12.26 ]\n",
      "  ...\n",
      "  [ -5.293  -5.055  -5.56  ...  -5.207  -5.664  -4.508]\n",
      "  [-10.17  -10.64  -10.67  ...  -9.55   -8.18  -10.38 ]\n",
      "  [-10.1   -10.61  -10.6   ...  -9.55   -8.195 -10.32 ]]], shape=(1, 110, 28996), dtype=float16)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast,TFBertForMaskedLM\n",
    "\n",
    "# https://huggingface.co/transformers/v3.0.2/model_doc/bert.html#berttokenizerfast\n",
    "tokenizer = BertTokenizerFast.from_pretrained(MODEL_BASE)\n",
    "MASK = tokenizer.mask_token\n",
    "\n",
    "masked_text = [f\"Jim Cramer is consistently bullish when it comes to {MASK}. What this means in practicality is that Cramer routinely recommends buying stocks, and he rarely offers up a sell call. Analysis of his recommendations between 2016 and 2022 (via the data project Jim Cramer's Recommendations: A Six-Year Analysis) shows a 10.32% distribution of {MASK} recommendations alongside 61.27% buys, plus a smattering of positive or negative commentary without a formal buy or sell recommendation attached.\"]\n",
    "\n",
    "inputs = tokenizer(masked_text, return_tensors=\"tf\", padding=True, truncation=True)\n",
    "\n",
    "model = TFBertForMaskedLM.from_pretrained(MODEL_BASE)\n",
    "logits = model(**inputs).logits\n",
    "mask_token_idxs = tf.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)\n",
    "print(mask_token_idxs)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db208fad",
   "metadata": {
    "_cell_guid": "2b826171-3c13-413c-9cea-f0b590af13c3",
    "_uuid": "7c6b679a-1210-4157-991a-f51bd8b4d49a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-04T21:41:55.096808Z",
     "iopub.status.busy": "2024-05-04T21:41:55.096529Z",
     "iopub.status.idle": "2024-05-04T21:41:55.170696Z",
     "shell.execute_reply": "2024-05-04T21:41:55.169708Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.086002,
     "end_time": "2024-05-04T21:41:55.172686",
     "exception": false,
     "start_time": "2024-05-04T21:41:55.086684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jim Cramer is consistently bullish when it comes to [buying:54.0%]. What this means in practicality is that Cramer routinely recommends buying stocks, and he rarely offers up a sell call. Analysis of his recommendations between 2016 and 2022 (via the data project Jim Cramer's Recommendations: A Six-Year Analysis) shows a 10.32% distribution of [his:56.5%] recommendations alongside 61.27% buys, plus a smattering of positive or negative commentary without a formal buy or sell recommendation attached.\n",
      "Jim Cramer is consistently bullish when it comes to [sales:14.3%]. What this means in practicality is that Cramer routinely recommends buying stocks, and he rarely offers up a sell call. Analysis of his recommendations between 2016 and 2022 (via the data project Jim Cramer's Recommendations: A Six-Year Analysis) shows a 10.32% distribution of [sales:17.4%] recommendations alongside 61.27% buys, plus a smattering of positive or negative commentary without a formal buy or sell recommendation attached.\n",
      "Jim Cramer is consistently bullish when it comes to [investing:13.0%]. What this means in practicality is that Cramer routinely recommends buying stocks, and he rarely offers up a sell call. Analysis of his recommendations between 2016 and 2022 (via the data project Jim Cramer's Recommendations: A Six-Year Analysis) shows a 10.32% distribution of [the:12.3%] recommendations alongside 61.27% buys, plus a smattering of positive or negative commentary without a formal buy or sell recommendation attached.\n",
      "Jim Cramer is consistently bullish when it comes to [selling:11.1%]. What this means in practicality is that Cramer routinely recommends buying stocks, and he rarely offers up a sell call. Analysis of his recommendations between 2016 and 2022 (via the data project Jim Cramer's Recommendations: A Six-Year Analysis) shows a 10.32% distribution of [stock:6.9%] recommendations alongside 61.27% buys, plus a smattering of positive or negative commentary without a formal buy or sell recommendation attached.\n",
      "Jim Cramer is consistently bullish when it comes to [purchases:7.7%]. What this means in practicality is that Cramer routinely recommends buying stocks, and he rarely offers up a sell call. Analysis of his recommendations between 2016 and 2022 (via the data project Jim Cramer's Recommendations: A Six-Year Analysis) shows a 10.32% distribution of [buying:6.9%] recommendations alongside 61.27% buys, plus a smattering of positive or negative commentary without a formal buy or sell recommendation attached.\n"
     ]
    }
   ],
   "source": [
    "mask_logits = tf.gather_nd(logits, mask_token_idxs)\n",
    "top_5 = tf.math.top_k(mask_logits, k=5)\n",
    "[tokenizer.decode([idx]) for idx in top_5.indices.numpy().flatten()]\n",
    "for i in range(5):\n",
    "    new_text = masked_text[0]\n",
    "    for j in range(2):\n",
    "        token_idx = top_5.indices[j, i]\n",
    "        top5_logits = top_5.values[j]\n",
    "\n",
    "        proba = tf.nn.softmax(top5_logits)\n",
    "        predicted_token = tokenizer.decode([token_idx])\n",
    "        new_text = new_text.replace(MASK, f'[{predicted_token}:{proba[i].numpy()*100.:.01f}%]', 1)\n",
    "    print(new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b628a89b",
   "metadata": {
    "_cell_guid": "637be554-6f63-4ad3-95fc-7c1852df72ff",
    "_uuid": "aad9dcf7-97b8-410f-a22d-d1cc6375940d",
    "papermill": {
     "duration": 0.008711,
     "end_time": "2024-05-04T21:41:55.191372",
     "exception": false,
     "start_time": "2024-05-04T21:41:55.182661",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Financial Conditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "574e863c",
   "metadata": {
    "_cell_guid": "9e8f9835-9379-4b37-8601-e4c8173a7a82",
    "_uuid": "141c04d4-e058-473e-8961-380676d5f807",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-04T21:41:55.210275Z",
     "iopub.status.busy": "2024-05-04T21:41:55.209984Z",
     "iopub.status.idle": "2024-05-04T21:41:55.367907Z",
     "shell.execute_reply": "2024-05-04T21:41:55.366992Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.169849,
     "end_time": "2024-05-04T21:41:55.370102",
     "exception": false,
     "start_time": "2024-05-04T21:41:55.200253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "text_dataset: 0it [00:00, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (4034 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs (len: 4034): [  101 10054 11522 ...   119  3254   102]\n",
      "Attention Mask: [[1 1 1 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "adapt_train_file = os.path.join(DATA_PATH, 'Domain_adapation/train.txt')\n",
    "adapt_test_file = os.path.join(DATA_PATH, 'Domain_adapation/dev.txt')\n",
    "def text_dataset(tokenizer, file_path):\n",
    "    def generator():\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for line in tqdm(file, desc=\"text_dataset\"):\n",
    "                tokens = tokenizer(line.strip(),\n",
    "                                   add_special_tokens=True,\n",
    "                                   truncation=False,\n",
    "                                   padding=False)\n",
    "                yield {\n",
    "                    'input_ids': tf.ragged.constant([tokens['input_ids']]),\n",
    "                    'attention_mask': tf.ragged.constant([tokens['attention_mask']])\n",
    "                }\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        generator,\n",
    "        output_signature={\n",
    "            'input_ids': tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int32),\n",
    "            'attention_mask': tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int32)\n",
    "        })\n",
    "\n",
    "train_dataset = text_dataset(tokenizer, adapt_train_file)\n",
    "eval_dataset = text_dataset(tokenizer, adapt_test_file)\n",
    "\n",
    "iterator = iter(eval_dataset.as_numpy_iterator())\n",
    "example = next(iterator)\n",
    "inputs = example['input_ids'][0]\n",
    "print(f\"Input IDs (len: {len(inputs)}):\", inputs)\n",
    "print(\"Attention Mask:\", example['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000c8392",
   "metadata": {
    "_cell_guid": "6d2cf351-350a-4c4f-abe0-823b9e54a914",
    "_uuid": "30c39754-c10b-4a87-a6d2-d53d991061f6",
    "papermill": {
     "duration": 0.008917,
     "end_time": "2024-05-04T21:41:55.389118",
     "exception": false,
     "start_time": "2024-05-04T21:41:55.380201",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The MLM needs chunked sequences which are comprised of the whole corpus concatenated. Chunks are sized on the given hardware or the max dictionary the  tokenizer has - in general 128 is a good number for modern hardward.\n",
    "\n",
    "As we concatenate, we add a lable column on which the MLM can use as a ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6f0de23",
   "metadata": {
    "_cell_guid": "bb0b6b2f-039a-4ffc-a657-9dae0ed14bab",
    "_uuid": "348780db-dba6-4b85-87ac-bd1bf0eaa66c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-04T21:41:55.408647Z",
     "iopub.status.busy": "2024-05-04T21:41:55.408365Z",
     "iopub.status.idle": "2024-05-04T21:42:20.331949Z",
     "shell.execute_reply": "2024-05-04T21:42:20.330997Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 24.935687,
     "end_time": "2024-05-04T21:42:20.333876",
     "exception": false,
     "start_time": "2024-05-04T21:41:55.398189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading file lines: 15463it [00:24, 624.74it/s]\n",
      "text_dataset: 1it [00:24, 24.96s/it]\n",
      "text_dataset: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs (len: 4034): [  101 10054 11522 ...   119  3254   102]\n",
      "Decoded IDs: [CLS] Lancaster Colony Reports Fourth Quarter and \n"
     ]
    }
   ],
   "source": [
    "def chunked_text_dataset(tokenizer, file_path, chunk_len=512):\n",
    "    all_tokens = []\n",
    "    all_attention_masks = []\n",
    "    all_special_tokens_masks = []\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in tqdm(file, desc=\"Reading file lines\", position=0, leave=True):\n",
    "            tokens = tokenizer(line.strip(),\n",
    "                               truncation=True,\n",
    "                               add_special_tokens=True,\n",
    "                               return_special_tokens_mask=True,\n",
    "                               padding=False)\n",
    "            all_tokens.extend(tokens['input_ids'])\n",
    "            all_attention_masks.extend(tokens['attention_mask'])\n",
    "            all_special_tokens_masks.extend(tokens['special_tokens_mask'])\n",
    "\n",
    "    def generator():\n",
    "        num_chunks = len(all_tokens) // chunk_len\n",
    "        for i in tqdm(range(num_chunks), desc= \"chunking...\", position=0, leave=True):\n",
    "            start = i * chunk_len\n",
    "            end = start + chunk_len\n",
    "            input_ids_chunk = all_tokens[start:end]\n",
    "            attention_mask_chunk = all_attention_masks[start:end]\n",
    "            special_tokens_mask_chunk = all_special_tokens_masks[start:end]\n",
    "            yield {\n",
    "                'input_ids': tf.convert_to_tensor(input_ids_chunk, dtype=tf.int32),\n",
    "                'attention_mask': tf.convert_to_tensor(attention_mask_chunk, dtype=tf.int32),\n",
    "                'labels': tf.convert_to_tensor(input_ids_chunk, dtype=tf.int32),\n",
    "                'special_tokens_mask': tf.convert_to_tensor(special_tokens_mask_chunk, dtype=tf.int32)\n",
    "            }\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        generator,\n",
    "        output_signature={\n",
    "            'input_ids': tf.TensorSpec(shape=(chunk_len,), dtype=tf.int32),\n",
    "            'attention_mask': tf.TensorSpec(shape=(chunk_len,), dtype=tf.int32),\n",
    "            'labels': tf.TensorSpec(shape=(chunk_len,), dtype=tf.int32),\n",
    "            'special_tokens_mask': tf.TensorSpec(shape=(chunk_len,), dtype=tf.int32)\n",
    "        })\n",
    "\n",
    "\n",
    "train_dataset = chunked_text_dataset(tokenizer, adapt_train_file)\n",
    "iterator = iter(eval_dataset.as_numpy_iterator())\n",
    "example = next(iterator)\n",
    "inputs = example['input_ids'][0]\n",
    "print(f\"Input IDs (len: {len(inputs)}):\", inputs)\n",
    "print(\"Decoded IDs:\", tokenizer.decode(inputs)[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbf586a",
   "metadata": {
    "_cell_guid": "412a902d-c4cf-4869-8ed3-0ee450656fb9",
    "_uuid": "4532d203-59ae-434c-ab86-4f33fee67904",
    "papermill": {
     "duration": 0.026505,
     "end_time": "2024-05-04T21:42:20.387681",
     "exception": false,
     "start_time": "2024-05-04T21:42:20.361176",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For MLMs huggingface offers a specific data collector that does the masking. Although we can mask random tokens using the `[MASK]` special token at random intervals, as long as there is a labals column with the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b57c57e",
   "metadata": {
    "_cell_guid": "b74d415d-ae9e-4f07-8682-f90ed5beb9c7",
    "_uuid": "9b74aa32-40f3-41ce-990b-25f2f5122bbf",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-04T21:42:20.442415Z",
     "iopub.status.busy": "2024-05-04T21:42:20.442093Z",
     "iopub.status.idle": "2024-05-04T21:42:25.810998Z",
     "shell.execute_reply": "2024-05-04T21:42:25.810073Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 5.398825,
     "end_time": "2024-05-04T21:42:25.813339",
     "exception": false,
     "start_time": "2024-05-04T21:42:20.414514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "text_dataset: 1it [00:00, 25.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'input_ids': array([  101, 10054, 11522, ...,   119,  3254,   102], dtype=int32), 'attention_mask': array([1, 1, 1, ..., 1, 1, 1], dtype=int32)}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "tokenizing batches: 0it [00:00, ?it/s]\u001b[A\n",
      "tokenizing batches: 1it [00:03,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked: [CLS] Lancaster [MASK] Reports Fourth Quarter and \n",
      "Labels: [ -100  -100 11522  -100  -100  -100  -100  -100  -100  -100  2381  -100\n",
      "  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100  -100  -100  2249  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100  -100 11896  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "  -100  -100]\n",
      "Original: [CLS] Lancaster Colony Reports Fourth Quarter and \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 4034), dtype=int64, numpy=array([[  101, 10054,   103, ...,   119,  3254,   102]])>, 'attention_mask': <tf.Tensor: shape=(1, 4034), dtype=int32, numpy=array([[1, 1, 1, ..., 1, 1, 1]], dtype=int32)>, 'labels': <tf.Tensor: shape=(1, 4034), dtype=int64, numpy=array([[ -100,  -100, 11522, ...,  -100,  -100,  -100]])>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DataCollatorForLanguageModeling, BertConfig\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15, return_tensors=\"tf\")\n",
    "batched_dataset = train_dataset.batch(1).take(1)\n",
    "\n",
    "batch = next(iter(eval_dataset.as_numpy_iterator()))\n",
    "batch = {k: v for k, v in batch.items()}\n",
    "examples = [{k: v[i] for k, v in batch.items()} for i in range(batch['input_ids'].shape[0])]\n",
    "print(examples)\n",
    "collated_batch = data_collator(examples)\n",
    "for input_ids, labels in tqdm(zip(collated_batch['input_ids'], collated_batch['labels']), desc=\"tokenizing batches\"):\n",
    "    masked_text = tokenizer.decode(input_ids)\n",
    "    original_text = tokenizer.decode([label if label != -100 else input_id for label, input_id in zip(labels, input_ids)])\n",
    "\n",
    "    print(f\"Masked: {masked_text[:50]}\")\n",
    "    print(f\"Labels: {labels[:50]}\")\n",
    "    print(f\"Original: {original_text[:50]}\")\n",
    "collated_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4799024",
   "metadata": {
    "_cell_guid": "7b87c510-53b6-411d-ac29-2df68475a302",
    "_uuid": "9b28577c-71e7-48cd-9886-bfeba0e93632",
    "papermill": {
     "duration": 0.02824,
     "end_time": "2024-05-04T21:42:25.872057",
     "exception": false,
     "start_time": "2024-05-04T21:42:25.843817",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Add everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb4a1a62",
   "metadata": {
    "_cell_guid": "c69123c9-0676-4a8a-90f1-341b3dab1436",
    "_uuid": "746ad547-16cc-4b67-9deb-caa8be6d9dae",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-04T21:42:25.931164Z",
     "iopub.status.busy": "2024-05-04T21:42:25.930299Z",
     "iopub.status.idle": "2024-05-04T21:43:31.353845Z",
     "shell.execute_reply": "2024-05-04T21:43:31.352882Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 65.45546,
     "end_time": "2024-05-04T21:43:31.355860",
     "exception": false,
     "start_time": "2024-05-04T21:42:25.900400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing file...: 15463it [00:24, 629.20it/s]\n",
      "Chunking...: 100%|██████████| 7675/7675 [00:32<00:00, 233.06it/s]\n",
      "Processing file...: 999it [00:02, 441.88it/s]\n",
      "Chunking...: 100%|██████████| 491/491 [00:02<00:00, 238.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'input_ids': array([  101, 10054, 11522, 16098,  7652, 12664,  1105, 17355, 26996,\n",
       "           103,  2381, 16005,   160,  9919, 12880,  2069, 23314, 23955,\n",
       "          2036,   117,  3197,   117, 16892,   119,  1765,   117, 12795,\n",
       "           120, 11629,  2249, 17540, 24952,   120,   118,   118,  7737,\n",
       "           103,  3436,   113,   103,  1116,  1810,  4426,   131, 10722,\n",
       "         15517,   114,  2052,  2103,  2686,  1111,  1103,  2223,  3861,\n",
       "          1105, 12087,  1214,  2207,  1340,  1476,   103, 12795,   119,\n",
       "           103, 13231,  1132,  1112,  3226,   131,  7652, 12664, 16005,\n",
       "         23582,  5795,   103,  5799,   121,   119,   130,   110,  1106,\n",
       "           109, 14116,   119,   130,  1550,  6055,   109,  2724,  1495,\n",
       "           119,   128,  1550,  1314,  1214,   119, 16409,  1665,  7535,\n",
       "          3408,  1155,  3813,  6547,  1106,   170,   103,  3880,  3311,\n",
       "          3694,  1121,  1103,  1379,  1479,   117,  1857,  7626,  5416,\n",
       "           152,  1306,   103, 18757,  4419,  1881,   117, 13511,   103,\n",
       "          3813,   103,   121,   119,   128,   110,   119, 11336, 11154,\n",
       "          5795,  3813, 20420,  1572,   119,   126,   110,  1106,   170,\n",
       "          1647,   109, 18868,   119,   125,  1550,   103,  1103, 15791,\n",
       "          1104,  1103, 18732, 23314,  2137,   103,  1627,  8010,  4466,\n",
       "           103,  4555,  1111,  1120,   118,  1313,  2094,  8160,   119,\n",
       "          1109, 16151,  1107, 11336, 11154,  5795,  3813,  1108,  1521,\n",
       "           103,  7958, 24861,  8162,   117, 17971,  5217, 11597,  1116,\n",
       "          1962,  1223,   170,   103,  3311,  1105,  7958,   103, 12205,\n",
       "           103,  1109,  6441,   103,   188,  2686,  1145, 21495,  1121,\n",
       "          2793,  4784,  1116,  1104,  1207,   103,   103,  1223,  5941,\n",
       "         11069,   117,  1259,  1126,  3631,   103,   103,  1423,   118,\n",
       "          5346,  6911,  5469,   103, 14313,  1116,  1105,   170,  2918,\n",
       "          3955,  2774,   103, 11318, 22675,   103, 20497,  1233,   118,\n",
       "           103, 14313,  1116,   119, 21015,  1200, 14301,  5795,  3813,\n",
       "          5799,  1572,   119,   122,   110,  1106,   109, 11965,   119,\n",
       "           125,  1550,   103, 11785,  1200, 14301,  3094,   103,  1108,\n",
       "          8362,  8057, 12198,  5382,  4401,  1118,  1103, 15791,  1104,\n",
       "           103, 23314,  2137,   118,  1627,   119,   103,   170,  1304,\n",
       "          3345,  1838,  1107,  1364,   117,  8440,  4555,  1120,   103,\n",
       "           118,  1555,  7724,  1189,   170,  2012,  7593,   103,  1318,\n",
       "          1105,  1340,   117,  1105,  3813,   103,  1168,  7724,  1145,\n",
       "          4725,  5087,  2032,  1103,  3861,   119, 23582, 10272,  5022,\n",
       "           103,   109,  1275,   119,   130,  1550,   117,  1137,  8176,\n",
       "           119,   130,   110,   117,  1106,   109,  5840,   103,   122,\n",
       "          1550,  4940,  1118,  1103, 11169,  3813,  5495,  5212,  1106,\n",
       "         11336, 11154,   117,  1412,  2616, 14095,  2648,  1105,  4725,\n",
       "          5795,  3945, 13192,  1107, 11336, 11154,   119,  1109, 10272,\n",
       "          5022,  2686,  1127,  8362,   103, 12198,  5382, 20968,  1118,\n",
       "          4692,  2272,  1106, 18732, 23314,  2137,   118,   103,   103,\n",
       "          1259,  2569, 24308, 12634,  5600,  1111,  1412,  1524,   118,\n",
       "          1413,  4570,  1373,   103,  1103,  2629,  1104, 19278, 21015,\n",
       "          1200, 14301,  6357,  1105,   103,  3389,   174,  3101, 27989,\n",
       "         15672,  1112,  1412, 11615,  1105,  3735,  6425,  3399, 13112,\n",
       "          1105,  7042, 19755,  2136,  1118,  1433,  2332,   103,  1106,\n",
       "          4609,  2914,  2500,   119,   156,  2349,   103,   138,   103,\n",
       "          3152,   109,   129,   119,   130,  1550,   117, 17841,  4940,\n",
       "          1118,   170,   109,   124,   119,   129,  1550,  2773,  1107,\n",
       "         24106,  1116,  1111,  4042,  1249,  8298,  1107,  1619,  1104,\n",
       "          1412, 23580,  2101,  1933,  1105,  2272,   103,  1107,  1901,\n",
       "          1106,   103,  6547,  1106,  1103, 15791,  1104, 18732, 23314,\n",
       "          2137,   118,  1627,   117,  1259,   170,  3593,   118,  1228,\n",
       "          1104,  3752,   103,  1111,   170, 11597,  2582,  4298,  1933,\n",
       "           119, 14104, 22863,  1107,  4555,  1206,   103,   102]),\n",
       "  'attention_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1]),\n",
       "  'labels': array([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          1233,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 10054,\n",
       "         11522,  -100,  -100, 11896,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,   117,  -100,  -100,\n",
       "          1693,  -100,  -100,  -100,  -100,   131,  -100,  -100,  -100,\n",
       "          -100,  -100,  3813,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  5335,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  1104,\n",
       "          -100,  -100,  2605,  -100,  -100,  -100,   117,  -100,  5795,\n",
       "          -100,  2569,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  1106,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  1112,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,   118,  -100,  -100,  -100,\n",
       "          2299,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  2773,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          1118,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  5941,  -100,  -100,  -100,  4014,  -100,\n",
       "           119,  -100,  -100,   112,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  2982,  1962,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  4733,  1104,  -100,  -100,\n",
       "          -100,  -100,  -100, 11237,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  1111,  -100,  2158,   118,  -100,  -100,  -100,\n",
       "           138,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  1112,  -100,  -100,  -100,  -100,  4555,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         18732,  -100,  -100,  -100,  -100,  -100,  1258,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  3613,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  1107,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  1111,  -100,  -100,  -100,\n",
       "          -100,  5087,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          4725,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  1492,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,   119,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          5022,  -100,  -100,  -100,  8057,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  1627,   117,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  1114,  -100,  -100,  -100,  2211,  -100,\n",
       "          -100,  -100,  -100,  -100,  3549,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  3912,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,   111,  -100, 11928,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  4940,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100, 11751,  -100,  -100,\n",
       "          -100,  4692,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100, 11928,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  4555,  -100,  1412,  -100])},)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = 512 # Default 256, MAX 512\n",
    "def mlm_text_dataset(file_path, tokenizer, data_collator, chunk_len=MAX_LEN):\n",
    "    all_tokens = []\n",
    "    all_attention_masks = []\n",
    "    all_special_tokens_masks = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in tqdm(file, position=0, leave=True, desc=\"Processing file...\"):\n",
    "            tokens = tokenizer(line.strip(),\n",
    "                               truncation=True,\n",
    "                               add_special_tokens=True,\n",
    "                               return_special_tokens_mask=True,\n",
    "                               padding=False)\n",
    "            all_tokens.extend(tokens['input_ids'])\n",
    "            all_attention_masks.extend(tokens['attention_mask'])\n",
    "            all_special_tokens_masks.extend(tokens['special_tokens_mask'])\n",
    "            \n",
    "\n",
    "    num_chunks = len(all_tokens) // chunk_len\n",
    "    tokens_chunks = []\n",
    "    attention_mask_chunks = []\n",
    "    label_chunks = []\n",
    "    special_tokens_mask_chunk=[]\n",
    "    for i in tqdm(range(num_chunks), position=0, leave=True, desc=\"Chunking...\"):\n",
    "        start = i * chunk_len\n",
    "        end = start + chunk_len\n",
    "        input_ids_chunk = all_tokens[start:end]\n",
    "        attention_mask_chunk = all_attention_masks[start:end]\n",
    "        special_tokens_mask_chunk = all_special_tokens_masks[start:end]\n",
    "\n",
    "        masked_chunks = data_collator([{\n",
    "                'input_ids': tf.convert_to_tensor(input_ids_chunk, dtype=tf.int32),\n",
    "                'attention_mask': tf.convert_to_tensor(attention_mask_chunk, dtype=tf.int32),\n",
    "                'special_tokens_mask': tf.convert_to_tensor(special_tokens_mask_chunk, dtype=tf.int32),}])\n",
    "        tokens_chunks.extend(masked_chunks['input_ids'])\n",
    "        label_chunks.extend(masked_chunks['labels'])\n",
    "        attention_mask_chunks.extend(masked_chunks['attention_mask'])\n",
    "        special_tokens_mask_chunk.extend(special_tokens_mask_chunk)\n",
    "    return tf.data.Dataset.from_tensor_slices((\n",
    "        {\n",
    "            'input_ids': tokens_chunks,\n",
    "            'attention_mask': attention_mask_chunks,\n",
    "            'labels': label_chunks,\n",
    "            # 'special_tokens_mask': special_tokens_mask_chunk\n",
    "        },\n",
    "    ))\n",
    "\n",
    "with strategy.scope():\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(MODEL_BASE)\n",
    "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15, return_tensors=\"np\")\n",
    "    mlm_train_dataset = mlm_text_dataset(adapt_train_file, tokenizer, data_collator)\n",
    "    mlm_test_dataset = mlm_text_dataset(adapt_test_file, tokenizer, data_collator)\n",
    "\n",
    "iterex = iter(mlm_test_dataset.as_numpy_iterator())\n",
    "next(iterex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c45a9e",
   "metadata": {
    "papermill": {
     "duration": 0.073216,
     "end_time": "2024-05-04T21:43:31.503377",
     "exception": false,
     "start_time": "2024-05-04T21:43:31.430161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## BERT Conditioning\n",
    "\n",
    "From the paper:\n",
    "\n",
    "* Batch size: 16, 32\n",
    "* Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
    "* Number of epochs: 2, 3, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ef5d420",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T21:43:31.697222Z",
     "iopub.status.busy": "2024-05-04T21:43:31.696298Z",
     "iopub.status.idle": "2024-05-04T21:43:46.643196Z",
     "shell.execute_reply": "2024-05-04T21:43:46.642093Z"
    },
    "papermill": {
     "duration": 15.068636,
     "end_time": "2024-05-04T21:43:46.645758",
     "exception": false,
     "start_time": "2024-05-04T21:43:31.577122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the weights of TFBertForMaskedLM were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n",
      "eval_mlm:   3%|▎         | 1/31 [00:00<00:15,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4236.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:   6%|▋         | 2/31 [00:00<00:13,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3956.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  10%|▉         | 3/31 [00:01<00:12,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3936.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  13%|█▎        | 4/31 [00:01<00:12,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3872.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  16%|█▌        | 5/31 [00:02<00:11,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3858.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  19%|█▉        | 6/31 [00:02<00:11,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4088.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  23%|██▎       | 7/31 [00:03<00:10,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4364.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  26%|██▌       | 8/31 [00:03<00:10,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4100.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  29%|██▉       | 9/31 [00:04<00:09,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3846.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  32%|███▏      | 10/31 [00:04<00:09,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4640.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  35%|███▌      | 11/31 [00:04<00:08,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4002.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  39%|███▊      | 12/31 [00:05<00:08,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4360.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  42%|████▏     | 13/31 [00:05<00:07,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3908.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  45%|████▌     | 14/31 [00:06<00:07,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4204.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  48%|████▊     | 15/31 [00:06<00:06,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3888.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  52%|█████▏    | 16/31 [00:07<00:06,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3908.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  55%|█████▍    | 17/31 [00:07<00:06,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4010.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  58%|█████▊    | 18/31 [00:07<00:05,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4484.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  61%|██████▏   | 19/31 [00:08<00:05,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4244.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  65%|██████▍   | 20/31 [00:08<00:04,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4296.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  68%|██████▊   | 21/31 [00:09<00:04,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3924.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  71%|███████   | 22/31 [00:09<00:03,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4264.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  74%|███████▍  | 23/31 [00:10<00:03,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4172.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  77%|███████▋  | 24/31 [00:10<00:03,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4210.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  81%|████████  | 25/31 [00:11<00:02,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4336.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  84%|████████▍ | 26/31 [00:11<00:02,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4300.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  87%|████████▋ | 27/31 [00:11<00:01,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4236.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  90%|█████████ | 28/31 [00:12<00:01,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4244.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  94%|█████████▎| 29/31 [00:12<00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3866.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  97%|█████████▋| 30/31 [00:13<00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4144.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm: 100%|██████████| 31/31 [00:13<00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2776.0, shape=(), dtype=float16)\n",
      "Average Cross-Entropy Loss: 3.3830089569091797\n",
      "Average Perplexity: 29.459278106689453\n",
      "Average Accuracy: 0.48690009117126465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync # Default 8\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "def eval_mlm(model, batched_dataset):\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.SUM)\n",
    "    total_loss = 0.\n",
    "    total_accuracy = 0.\n",
    "    total_examples = 0.\n",
    "\n",
    "    # TODO: convert this to a TF function for distributed strat.\n",
    "    for batch in tqdm(batched_dataset, desc=\"eval_mlm\", position=0, leave=True):\n",
    "        for dataset_output in batch:\n",
    "            input_ids = dataset_output['input_ids']\n",
    "            attention_mask = dataset_output['attention_mask']\n",
    "            labels = dataset_output['labels']\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            mask = (labels != -100)\n",
    "            masked_logits = tf.boolean_mask(logits, mask)\n",
    "            masked_labels = tf.boolean_mask(labels, mask)\n",
    "            batch_loss = loss_fn(masked_labels, masked_logits)\n",
    "            predictions = tf.argmax(masked_logits, axis=-1)\n",
    "            batch_accuracy = tf.reduce_sum(tf.cast(tf.equal(predictions, masked_labels), dtype=tf.float32))\n",
    "            print(batch_loss)\n",
    "\n",
    "            total_loss += tf.cast(batch_loss,tf.float32)\n",
    "            total_accuracy += batch_accuracy\n",
    "            total_examples += tf.size(masked_labels, out_type=tf.float32)\n",
    "\n",
    "    avg_loss = total_loss / total_examples\n",
    "    avg_perplexity = tf.exp(avg_loss).numpy()\n",
    "    avg_accuracy = total_accuracy / total_examples\n",
    "\n",
    "    print(f\"Average Cross-Entropy Loss: {avg_loss.numpy()}\")\n",
    "    print(f\"Average Perplexity: {avg_perplexity}\")\n",
    "    print(f\"Average Accuracy: {avg_accuracy.numpy()}\")\n",
    "\n",
    "config = BertConfig.from_pretrained(MODEL_BASE)\n",
    "model = TFBertForMaskedLM.from_pretrained(MODEL_BASE, config=config)\n",
    "test_dataset = mlm_test_dataset.shuffle(buffer_size=BUFFER_SIZE).batch(BATCH_SIZE).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "eval_mlm(model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4649c44e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T21:43:46.809793Z",
     "iopub.status.busy": "2024-05-04T21:43:46.809500Z",
     "iopub.status.idle": "2024-05-04T21:43:46.815477Z",
     "shell.execute_reply": "2024-05-04T21:43:46.814436Z"
    },
    "papermill": {
     "duration": 0.090448,
     "end_time": "2024-05-04T21:43:46.817614",
     "exception": false,
     "start_time": "2024-05-04T21:43:46.727166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 512 # Default 256, MAX 512\n",
    "LEARN_RATE=5e-5 # 5e-5\n",
    "PATIENCE=10\n",
    "EPOCHS=50\n",
    "\n",
    "TOTAL_STEPS = 100000 \n",
    "WARM_STEPS = 10000\n",
    "INIT_LR = 1e-4\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.999\n",
    "WEIGHT_DECAY = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "799603ff",
   "metadata": {
    "_cell_guid": "b8542448-aed9-4324-9759-cf47b37b5f47",
    "_uuid": "191e97fc-b9b1-4835-870d-4ad8be04a881",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-04T21:43:46.978572Z",
     "iopub.status.busy": "2024-05-04T21:43:46.978007Z",
     "iopub.status.idle": "2024-05-04T23:48:13.954718Z",
     "shell.execute_reply": "2024-05-04T23:48:13.953745Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 7467.060186,
     "end_time": "2024-05-04T23:48:13.957173",
     "exception": false,
     "start_time": "2024-05-04T21:43:46.896987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the weights of TFBertForMaskedLM were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING: AutoGraph could not transform <function infer_framework at 0x7a624c8e3e20> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function create_autocast_variable at 0x7a664bf94280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <gast.gast.Expr object at 0x7a62141ca350>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1714859119.852272      71 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 729s 1s/step - loss: 2.6895 - val_loss: 2.1238\n",
      "Epoch 2/50\n",
      "480/480 [==============================] - 613s 1s/step - loss: 1.5811 - val_loss: 1.5912\n",
      "Epoch 3/50\n",
      "480/480 [==============================] - 613s 1s/step - loss: 1.1749 - val_loss: 1.6002\n",
      "Epoch 4/50\n",
      "480/480 [==============================] - 612s 1s/step - loss: 0.9518 - val_loss: 1.6507\n",
      "Epoch 5/50\n",
      "480/480 [==============================] - 611s 1s/step - loss: 0.7690 - val_loss: 1.7096\n",
      "Epoch 6/50\n",
      "480/480 [==============================] - 611s 1s/step - loss: 0.6182 - val_loss: 1.7693\n",
      "Epoch 7/50\n",
      "480/480 [==============================] - 612s 1s/step - loss: 0.4905 - val_loss: 1.8190\n",
      "Epoch 8/50\n",
      "480/480 [==============================] - 612s 1s/step - loss: 0.3898 - val_loss: 1.8678\n",
      "Epoch 9/50\n",
      "480/480 [==============================] - 612s 1s/step - loss: 0.3132 - val_loss: 1.8982\n",
      "Epoch 10/50\n",
      "480/480 [==============================] - 613s 1s/step - loss: 0.2473 - val_loss: 1.9434\n",
      "Epoch 11/50\n",
      "480/480 [==============================] - 612s 1s/step - loss: 0.1993 - val_loss: 1.9809\n",
      "Epoch 12/50\n",
      "480/480 [==============================] - 612s 1s/step - loss: 0.1639 - val_loss: 2.0025\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, TerminateOnNaN\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    # https://huggingface.co/transformers/v3.0.2/_modules/transformers/configuration_bert.html#BertConfig\n",
    "    config = BertConfig.from_pretrained(MODEL_BASE)\n",
    "    cond_model = TFBertForMaskedLM.from_pretrained(MODEL_BASE, config=config)\n",
    "    \n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard\n",
    "    tensorboard_callback = TensorBoard(log_dir=f\"{MODEL_PATH}/logs\",\n",
    "                                        histogram_freq=2,\n",
    "                                        embeddings_freq=2)\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n",
    "    early_stopping = EarlyStopping(mode='min', patience=PATIENCE, start_from_epoch=1)\n",
    "    #tf.debugging.enable_check_numerics() # - Assert if no Infs or NaNs go through. not for TPU!\n",
    "    #tf.config.run_functions_eagerly(not is_tpu_strategy(strategy)) # - Easy debugging\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\n",
    "    train_dataset = (mlm_train_dataset.shuffle(buffer_size=BUFFER_SIZE)\n",
    "                                    .batch(BATCH_SIZE)\n",
    "                                    .cache()\n",
    "                                    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "    test_dataset = (mlm_test_dataset.shuffle(buffer_size=BUFFER_SIZE)\n",
    "                                    .batch(BATCH_SIZE)\n",
    "                                    .cache()\n",
    "                                    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "    cond_model.compile(optimizer=AdamW(learning_rate=LEARN_RATE))\n",
    "    history = cond_model.fit(train_dataset,\n",
    "                        epochs=EPOCHS,\n",
    "                        callbacks=[early_stopping, TerminateOnNaN()],\n",
    "                        verbose=\"auto\",\n",
    "                        validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa0b1bf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T23:48:15.057270Z",
     "iopub.status.busy": "2024-05-04T23:48:15.056932Z",
     "iopub.status.idle": "2024-05-04T23:48:16.842206Z",
     "shell.execute_reply": "2024-05-04T23:48:16.841441Z"
    },
    "papermill": {
     "duration": 2.329967,
     "end_time": "2024-05-04T23:48:16.844370",
     "exception": false,
     "start_time": "2024-05-04T23:48:14.514403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# CAn get very big if run in kaggle\n",
    "SAVE_ZIP = False\n",
    "cond_model.save_pretrained(f\"{MODEL_PATH}/model\")\n",
    "config.save_pretrained(f\"{MODEL_PATH}/config\")\n",
    "tokenizer.save_pretrained(f\"{MODEL_PATH}/tokenizer\")\n",
    "\n",
    "if SAVE_ZIP:\n",
    "    def zip_models(directory, output_filename, compression_level = 9):\n",
    "        with zipfile.ZipFile(output_filename, 'w', zipfile.ZIP_DEFLATED, compresslevel=compression_level) as zipf:\n",
    "            for root, dirs, files in os.walk(directory):\n",
    "                for file in files:\n",
    "                    zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), os.path.join(directory, '..')))    \n",
    "\n",
    "    zip_models(MODEL_PATH, './cond_bert.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37117f87",
   "metadata": {
    "papermill": {
     "duration": 0.538194,
     "end_time": "2024-05-04T23:48:17.919027",
     "exception": false,
     "start_time": "2024-05-04T23:48:17.380833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Entropy\n",
    "\n",
    "Entropy is a measure that quantifies uncertainty or the inverse of probability of an event occurring;h igher the probability, lesser is the uncertainty. \n",
    "\n",
    "\n",
    "Hence, the goal of the language model is to minimize the entropy of generating a sequence of words that are similar to the training sequences. The formula for calculating Entropy is as given below where P(x) is the probability of the word x:\n",
    "\n",
    "$$\n",
    "H(X) = -\\sum_{i=1}^n P(x_i) \\log_b P(x_i)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "* H(X) is the entropy of the random variable X, which represents the different outcomes in the language model\n",
    "* P(x_i) is the probability of occurrence of each outcome x_i\n",
    "* n is the number of possible outcomes.\n",
    "* logb is the logarithm base, e.g base 2 for binary entropy calculations.\n",
    "\n",
    "Cross enthropy measures 2 distributions the true outcome distributions and the models. Using the equaltion above the second p(x_i) is replaced with the models distribution.\n",
    "\n",
    "# Perplexity\n",
    "\n",
    "Perplexity means the model is surprised to see new data. The lower the perplexity, the better the training is.\n",
    "\n",
    "The formula for perplexity is the exponent of mean of log likelihood of all the words in an input sequence:\n",
    "\n",
    "$$\n",
    "\\text{PPL}(X) = \\exp\\left(-\\frac{1}{T} \\sum_{i=1}^T \\log p_{\\theta}(x_i | x_{< i}) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccdca2fd",
   "metadata": {
    "_cell_guid": "3cd36b7d-2802-4ee6-a86b-53cddbc0462b",
    "_uuid": "45ef33b8-5150-43d1-8695-1cdcc1c518e0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-04T23:48:19.053474Z",
     "iopub.status.busy": "2024-05-04T23:48:19.053101Z",
     "iopub.status.idle": "2024-05-04T23:48:19.062303Z",
     "shell.execute_reply": "2024-05-04T23:48:19.061430Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.553243,
     "end_time": "2024-05-04T23:48:19.064611",
     "exception": false,
     "start_time": "2024-05-04T23:48:18.511368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': 0.16385002434253693,\n",
       " 'train_perplexity': 1.1780376248761306,\n",
       " 'eval_loss': 2.0024571418762207,\n",
       " 'eval_perplexity': 7.407234382261664}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_loss = history.history[\"loss\"][-1]\n",
    "try:\n",
    "    train_perplexity = math.exp(train_loss)\n",
    "except OverflowError:\n",
    "    train_perplexity = math.inf\n",
    "validation_loss = history.history[\"val_loss\"][-1]\n",
    "try:\n",
    "    validation_perplexity = math.exp(validation_loss)\n",
    "except OverflowError:\n",
    "    validation_perplexity = math.inf\n",
    "results_dict = {}\n",
    "results_dict[\"train_loss\"] = train_loss\n",
    "results_dict[\"train_perplexity\"] = train_perplexity\n",
    "results_dict[\"eval_loss\"] = validation_loss\n",
    "results_dict[\"eval_perplexity\"] = validation_perplexity\n",
    "\n",
    "\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f728067d",
   "metadata": {
    "papermill": {
     "duration": 0.541864,
     "end_time": "2024-05-04T23:48:20.141464",
     "exception": false,
     "start_time": "2024-05-04T23:48:19.599600",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluate Conditioned\n",
    "\n",
    "Base:\n",
    "\n",
    "1. Average Cross-Entropy Loss: 3.3887569904327393\n",
    "1. Average Perplexity: 29.629100799560547\n",
    "1. Average Accuracy: 0.48579704761505127\n",
    "\n",
    "Conditioned:\n",
    "\n",
    "* Average Cross-Entropy Loss: 7.493394374847412\n",
    "* Average Perplexity: 1796.1385498046875\n",
    "* Average Accuracy: 0.02848563715815544"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30742f7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T23:48:21.279729Z",
     "iopub.status.busy": "2024-05-04T23:48:21.279348Z",
     "iopub.status.idle": "2024-05-04T23:48:36.211949Z",
     "shell.execute_reply": "2024-05-04T23:48:36.210901Z"
    },
    "papermill": {
     "duration": 15.532247,
     "end_time": "2024-05-04T23:48:36.213808",
     "exception": false,
     "start_time": "2024-05-04T23:48:20.681561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at ././models/model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n",
      "eval_mlm:   3%|▎         | 1/31 [00:00<00:13,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2718.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:   6%|▋         | 2/31 [00:00<00:12,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2380.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  10%|▉         | 3/31 [00:01<00:12,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2314.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  13%|█▎        | 4/31 [00:01<00:11,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2003.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  16%|█▌        | 5/31 [00:02<00:11,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2222.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  19%|█▉        | 6/31 [00:02<00:11,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2638.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  23%|██▎       | 7/31 [00:03<00:10,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2130.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  26%|██▌       | 8/31 [00:03<00:10,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2548.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  29%|██▉       | 9/31 [00:03<00:09,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2522.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  32%|███▏      | 10/31 [00:04<00:09,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2212.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  35%|███▌      | 11/31 [00:04<00:08,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2558.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  39%|███▊      | 12/31 [00:05<00:08,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2424.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  42%|████▏     | 13/31 [00:05<00:07,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2638.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  45%|████▌     | 14/31 [00:06<00:07,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2448.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  48%|████▊     | 15/31 [00:06<00:07,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2672.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  52%|█████▏    | 16/31 [00:07<00:06,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2472.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  55%|█████▍    | 17/31 [00:07<00:06,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2514.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  58%|█████▊    | 18/31 [00:07<00:05,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2410.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  61%|██████▏   | 19/31 [00:08<00:05,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2488.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  65%|██████▍   | 20/31 [00:08<00:04,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2408.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  68%|██████▊   | 21/31 [00:09<00:04,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2496.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  71%|███████   | 22/31 [00:09<00:03,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2836.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  74%|███████▍  | 23/31 [00:10<00:03,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2144.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  77%|███████▋  | 24/31 [00:10<00:03,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2472.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  81%|████████  | 25/31 [00:11<00:02,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2192.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  84%|████████▍ | 26/31 [00:11<00:02,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2592.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  87%|████████▋ | 27/31 [00:11<00:01,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2322.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  90%|█████████ | 28/31 [00:12<00:01,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2812.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  94%|█████████▎| 29/31 [00:12<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2732.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm:  97%|█████████▋| 30/31 [00:13<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2226.0, shape=(), dtype=float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_mlm: 100%|██████████| 31/31 [00:13<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1521.0, shape=(), dtype=float16)\n",
      "Average Cross-Entropy Loss: 2.004753828048706\n",
      "Average Perplexity: 7.424266338348389\n",
      "Average Accuracy: 0.6953235864639282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config = BertConfig.from_pretrained(f\"./{MODEL_PATH}/config\")\n",
    "model = TFBertForMaskedLM.from_pretrained(f\"./{MODEL_PATH}/model\", config=config)\n",
    "test_dataset = mlm_test_dataset.shuffle(buffer_size=10000).batch(BATCH_SIZE).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "eval_mlm(model, test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "datasetId": 4755137,
     "sourceId": 8061237,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7635.518203,
   "end_time": "2024-05-04T23:48:39.822894",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-04T21:41:24.304691",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0456aea70c9648fa954de65a81fac944": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "09470e087a1c4d79b36d638f1deeb064": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0aabac4a7a6c4097a2875d709aca3cfc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0f403426fc80406d837ef2db008304e1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1eac1bff70ec4aa6b90226434bed2eb0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "242200cd0998416181456388d689f464": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2726ed34670d47f28cc2bdb6d5f96a0f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2966ada7e787484fb211aa5603eecf18": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0456aea70c9648fa954de65a81fac944",
       "placeholder": "​",
       "style": "IPY_MODEL_f385ed4f06b7466481906c0dfce4a892",
       "value": "config.json: 100%"
      }
     },
     "348a54b37b8643649b819297ef45c0fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "368c3c076c784cefa7e82bedf208bfb9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "41dc1c892c544da0b3d23c729a61e656": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d0737cbdcb184f168ae94db58345101d",
       "placeholder": "​",
       "style": "IPY_MODEL_edbfd2f88b334360aa0a91301537ba6f",
       "value": " 570/570 [00:00&lt;00:00, 51.6kB/s]"
      }
     },
     "4e417648fea94ae0857f917fb38330da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5754eda83acb4ab9986fdd62090cfcab": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "662feb60037d44a78facaf29a77275fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "665e4a87d6fe473eaaeaa22ed7792278": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6ecc56e39730456fab70474c6199da13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_09470e087a1c4d79b36d638f1deeb064",
       "max": 435755784.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8b9e775e29a24f65a32be5fd8c270970",
       "value": 435755784.0
      }
     },
     "773bf1e808d4490aa3e96d4b017ef7a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "78db439fbb104af2988831eb3298443d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7937dff3a2bd41debd95192d4bfd7fc3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7e9c53420dfb4854ae8e64e5a3e9f187": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c5ddc030e50842eaa126237166d7c726",
       "max": 213450.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e3254885ef64435e82a2ce11dbc3c10f",
       "value": 213450.0
      }
     },
     "7f33783c970c473494031c09f1a8431e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_aee8a32ac45c432ab842dbd3458ab690",
        "IPY_MODEL_9fe904d0929746b29b5bf134e566bad7",
        "IPY_MODEL_f2460fd0af424adbb666f10d621b0199"
       ],
       "layout": "IPY_MODEL_99cb442ae1624288ad27cb6256141b45"
      }
     },
     "8b9e775e29a24f65a32be5fd8c270970": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8bb4820c3abc44248dce2273e9e15650": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f5c78040fffb404ca2b4f819efe7da0f",
        "IPY_MODEL_c8915407d31c48d493ef068af64e2252",
        "IPY_MODEL_eedeecdfe4184d0e8d074c6a16b7f44c"
       ],
       "layout": "IPY_MODEL_c6c0d37893a145b6b03af24424012414"
      }
     },
     "8d18474e66e74950bfac4475c8b19584": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "92b5741ebc1f46da96710085a5cc436e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_eaba011831234cde8bfd04d79c42b08c",
        "IPY_MODEL_6ecc56e39730456fab70474c6199da13",
        "IPY_MODEL_c465eedfd38e482d9e4ae04624e0a5e0"
       ],
       "layout": "IPY_MODEL_c54a171e852b459691f38b86ab1965ad"
      }
     },
     "96949a5329ca4ec1aa7a8f208dfa2551": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "99cb442ae1624288ad27cb6256141b45": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9fe904d0929746b29b5bf134e566bad7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0f403426fc80406d837ef2db008304e1",
       "max": 435797.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7937dff3a2bd41debd95192d4bfd7fc3",
       "value": 435797.0
      }
     },
     "a29970d21e45488d85f8cd08f41ce0e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_368c3c076c784cefa7e82bedf208bfb9",
       "placeholder": "​",
       "style": "IPY_MODEL_773bf1e808d4490aa3e96d4b017ef7a3",
       "value": " 213k/213k [00:00&lt;00:00, 7.30MB/s]"
      }
     },
     "aee8a32ac45c432ab842dbd3458ab690": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2726ed34670d47f28cc2bdb6d5f96a0f",
       "placeholder": "​",
       "style": "IPY_MODEL_8d18474e66e74950bfac4475c8b19584",
       "value": "tokenizer.json: 100%"
      }
     },
     "b1b00bd29b394e14bc292b63a0a5a914": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bc5f33f7be624c8ba01443a268f3f63b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2966ada7e787484fb211aa5603eecf18",
        "IPY_MODEL_e4c454490bbe464197794fa72da4bd0a",
        "IPY_MODEL_41dc1c892c544da0b3d23c729a61e656"
       ],
       "layout": "IPY_MODEL_f988625b9e9042699f537cdbf2ef955e"
      }
     },
     "c465eedfd38e482d9e4ae04624e0a5e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d20fac256b5945708d662c799ef20df6",
       "placeholder": "​",
       "style": "IPY_MODEL_f209e7c2edd042ccb15ffdccd7261c89",
       "value": " 436M/436M [00:01&lt;00:00, 318MB/s]"
      }
     },
     "c54a171e852b459691f38b86ab1965ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c5ddc030e50842eaa126237166d7c726": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c6c0d37893a145b6b03af24424012414": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c8915407d31c48d493ef068af64e2252": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b1b00bd29b394e14bc292b63a0a5a914",
       "max": 49.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1eac1bff70ec4aa6b90226434bed2eb0",
       "value": 49.0
      }
     },
     "d03a09073c87402b9da3428d157b95dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d0737cbdcb184f168ae94db58345101d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d20fac256b5945708d662c799ef20df6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d32ff371ad8d48a49bd12ea1ece9be75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e42f3c5243e14cc6bb6a1b01c6ef143a",
       "placeholder": "​",
       "style": "IPY_MODEL_348a54b37b8643649b819297ef45c0fb",
       "value": "vocab.txt: 100%"
      }
     },
     "da732ad3a2ea4ce88adea0d79c09443e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d32ff371ad8d48a49bd12ea1ece9be75",
        "IPY_MODEL_7e9c53420dfb4854ae8e64e5a3e9f187",
        "IPY_MODEL_a29970d21e45488d85f8cd08f41ce0e9"
       ],
       "layout": "IPY_MODEL_fa50ab0d2155424492bb1fc03a59322f"
      }
     },
     "dd5781a72d35405dbedc3ec4f8e808c3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e3254885ef64435e82a2ce11dbc3c10f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e42f3c5243e14cc6bb6a1b01c6ef143a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e4c454490bbe464197794fa72da4bd0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_78db439fbb104af2988831eb3298443d",
       "max": 570.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_665e4a87d6fe473eaaeaa22ed7792278",
       "value": 570.0
      }
     },
     "eaba011831234cde8bfd04d79c42b08c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dd5781a72d35405dbedc3ec4f8e808c3",
       "placeholder": "​",
       "style": "IPY_MODEL_242200cd0998416181456388d689f464",
       "value": "model.safetensors: 100%"
      }
     },
     "edbfd2f88b334360aa0a91301537ba6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "eedeecdfe4184d0e8d074c6a16b7f44c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_662feb60037d44a78facaf29a77275fa",
       "placeholder": "​",
       "style": "IPY_MODEL_d03a09073c87402b9da3428d157b95dd",
       "value": " 49.0/49.0 [00:00&lt;00:00, 4.24kB/s]"
      }
     },
     "f209e7c2edd042ccb15ffdccd7261c89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f2460fd0af424adbb666f10d621b0199": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_96949a5329ca4ec1aa7a8f208dfa2551",
       "placeholder": "​",
       "style": "IPY_MODEL_4e417648fea94ae0857f917fb38330da",
       "value": " 436k/436k [00:00&lt;00:00, 6.81MB/s]"
      }
     },
     "f385ed4f06b7466481906c0dfce4a892": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f5c78040fffb404ca2b4f819efe7da0f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5754eda83acb4ab9986fdd62090cfcab",
       "placeholder": "​",
       "style": "IPY_MODEL_0aabac4a7a6c4097a2875d709aca3cfc",
       "value": "tokenizer_config.json: 100%"
      }
     },
     "f988625b9e9042699f537cdbf2ef955e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fa50ab0d2155424492bb1fc03a59322f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
